{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YPRlQGWHiU5M2jgNpUdne5lceLeqBeYW",
      "authorship_tag": "ABX9TyNcnVOcmojoXaFHeneqmSVJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkurGuptaGithub/Signboard-Translation/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrZgk1wN1MWg"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APTOqdbe6b9K"
      },
      "source": [
        "class Model(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Model, self).__init__()\r\n",
        "        all_feat_cols=range(132)\r\n",
        "        self.batch_norm0 = nn.BatchNorm1d(len(all_feat_cols))\r\n",
        "        self.dropout0 = nn.Dropout(0.2)\r\n",
        "\r\n",
        "        dropout_rate = 0.2\r\n",
        "        hidden_size = 256\r\n",
        "        self.dense1 = nn.Linear(len(all_feat_cols), hidden_size)\r\n",
        "        self.batch_norm1 = nn.BatchNorm1d(hidden_size)\r\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\r\n",
        "\r\n",
        "        self.dense2 = nn.Linear(hidden_size+len(all_feat_cols), hidden_size)\r\n",
        "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\r\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\r\n",
        "\r\n",
        "        self.dense3 = nn.Linear(hidden_size+hidden_size, hidden_size)\r\n",
        "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\r\n",
        "        self.dropout3 = nn.Dropout(dropout_rate)\r\n",
        "\r\n",
        "        self.dense4 = nn.Linear(hidden_size+hidden_size, hidden_size)\r\n",
        "        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\r\n",
        "        self.dropout4 = nn.Dropout(dropout_rate)\r\n",
        "\r\n",
        "        self.dense5 = nn.Linear(hidden_size+hidden_size, 5)\r\n",
        "\r\n",
        "        self.Relu = nn.ReLU(inplace=True)\r\n",
        "        self.PReLU = nn.PReLU()\r\n",
        "        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01, inplace=True)\r\n",
        "        # self.GeLU = nn.GELU()\r\n",
        "        self.RReLU = nn.RReLU()\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.batch_norm0(x)\r\n",
        "        x = self.dropout0(x)\r\n",
        "\r\n",
        "        x1 = self.dense1(x)\r\n",
        "        x1 = self.batch_norm1(x1)\r\n",
        "        # x = F.relu(x)\r\n",
        "        # x = self.PReLU(x)\r\n",
        "        x1 = self.LeakyReLU(x1)\r\n",
        "        x1 = self.dropout1(x1)\r\n",
        "\r\n",
        "        x = torch.cat([x, x1], 1)\r\n",
        "\r\n",
        "        x2 = self.dense2(x)\r\n",
        "        x2 = self.batch_norm2(x2)\r\n",
        "        # x = F.relu(x)\r\n",
        "        # x = self.PReLU(x)\r\n",
        "        x2 = self.LeakyReLU(x2)\r\n",
        "        x2 = self.dropout2(x2)\r\n",
        "\r\n",
        "        x = torch.cat([x1, x2], 1)\r\n",
        "\r\n",
        "        x3 = self.dense3(x)\r\n",
        "        x3 = self.batch_norm3(x3)\r\n",
        "        # x = F.relu(x)\r\n",
        "        # x = self.PReLU(x)\r\n",
        "        x3 = self.LeakyReLU(x3)\r\n",
        "        x3 = self.dropout3(x3)\r\n",
        "\r\n",
        "        x = torch.cat([x2, x3], 1)\r\n",
        "\r\n",
        "        x4 = self.dense4(x)\r\n",
        "        x4 = self.batch_norm4(x4)\r\n",
        "        # x = F.relu(x)\r\n",
        "        # x = self.PReLU(x)\r\n",
        "        x4 = self.LeakyReLU(x4)\r\n",
        "        x4 = self.dropout4(x4)\r\n",
        "\r\n",
        "        x = torch.cat([x3, x4], 1)\r\n",
        "\r\n",
        "        x = self.dense5(x)\r\n",
        "\r\n",
        "        return x\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ2EIbjh6ojc"
      },
      "source": [
        "model2= Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ3XM6A85szK",
        "outputId": "1e0b18ef-e9e8-42a2-9dc7-edf2ae35499e"
      },
      "source": [
        "model2.load_state_dict(torch.load('online_model0.pth'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koLYwqux72N-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57ef220f-7609-4f9c-ae71-a9d7913df027"
      },
      "source": [
        "model2.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('batch_norm0.weight',\n",
              "              tensor([0.3505, 0.2582, 0.2861, 0.7069, 0.6943, 0.8224, 0.7258, 0.3879, 0.3686,\n",
              "                      0.2151, 0.2821, 0.1994, 0.2350, 0.1709, 0.1618, 0.1758, 0.2258, 0.3051,\n",
              "                      0.2740, 0.2284, 0.2847, 0.1944, 0.1916, 0.1877, 0.1915, 0.1729, 0.2187,\n",
              "                      0.3581, 0.3429, 0.2424, 0.2832, 0.1931, 0.2151, 0.2158, 0.2227, 0.2216,\n",
              "                      0.2038, 0.5088, 0.4582, 0.7135, 0.5157, 0.7675, 0.3809, 0.7102, 0.8140,\n",
              "                      0.7068, 0.2728, 0.3622, 0.3339, 0.3714, 0.3049, 0.4268, 0.2999, 0.2699,\n",
              "                      0.2436, 0.6277, 0.3075, 0.4627, 0.4614, 0.3585, 0.5168, 0.5107, 0.5007,\n",
              "                      0.5139, 0.8710, 0.4882, 0.4597, 0.4567, 0.4359, 0.3248, 0.3153, 0.3393,\n",
              "                      0.3568, 0.1911, 0.2407, 0.1513, 0.1537, 0.6260, 0.3495, 0.1541, 0.2024,\n",
              "                      0.1205, 0.0990, 0.6080, 0.3746, 0.2756, 0.3235, 0.2402, 0.2249, 0.3929,\n",
              "                      0.2553, 0.2188, 0.1661, 0.1676, 0.1280, 0.3215, 0.3365, 0.2354, 0.2646,\n",
              "                      0.2047, 0.2384, 0.4237, 0.2351, 0.1444, 0.2167, 0.1559, 0.1578, 0.3401,\n",
              "                      0.3323, 0.2745, 0.2562, 0.2207, 0.1985, 0.4070, 0.2388, 0.2516, 0.1748,\n",
              "                      0.1377, 0.1323, 0.3250, 0.4027, 0.5523, 0.2833, 0.2269, 0.3423, 0.4452,\n",
              "                      0.3039, 0.3585, 0.2573, 0.2388, 0.6937, 0.0838])),\n",
              "             ('batch_norm0.bias',\n",
              "              tensor([-6.1205e-02,  6.5622e-03,  7.7305e-03,  4.1214e-02,  4.5302e-02,\n",
              "                       1.3215e-02,  5.5424e-02, -9.0795e-03, -2.9433e-02, -1.1581e-02,\n",
              "                      -8.2268e-02, -2.3303e-02, -1.5552e-02,  7.7227e-03, -2.4340e-02,\n",
              "                      -7.8605e-03, -5.4151e-02,  3.1087e-03, -7.0588e-03, -2.7095e-02,\n",
              "                      -1.3022e-01,  2.2722e-02, -4.1967e-02,  1.7263e-03,  6.5324e-03,\n",
              "                       3.9320e-03,  1.1092e-02,  6.4976e-02,  8.8349e-02,  1.0940e-02,\n",
              "                       2.8281e-02,  2.5385e-03,  1.5345e-03,  5.3967e-02,  3.3813e-02,\n",
              "                       5.2224e-02, -2.5586e-02, -4.3642e-02, -2.9997e-02,  1.3706e-01,\n",
              "                       8.2895e-02, -2.5532e-01,  1.8337e-01,  3.2809e-01, -9.9214e-02,\n",
              "                      -3.6071e-01,  2.0907e-02,  2.0307e-02,  7.0417e-03,  2.3995e-02,\n",
              "                      -2.3381e-02,  2.7904e-03, -8.3335e-02,  4.2926e-02,  5.1034e-03,\n",
              "                       6.1990e-02, -1.6758e-02,  4.7465e-02,  2.0460e-02,  4.2849e-02,\n",
              "                      -3.8439e-02, -5.2692e-02, -9.7704e-02, -9.3156e-02, -6.6950e-01,\n",
              "                       3.4871e-02,  3.2044e-02,  2.5752e-02,  3.3463e-02,  4.8007e-02,\n",
              "                      -4.1276e-02, -2.3416e-02,  1.1987e-02, -1.3490e-03,  1.8179e-02,\n",
              "                       6.9810e-03,  7.5506e-04, -9.2867e-02, -3.2107e-02,  2.4745e-03,\n",
              "                       4.0562e-02,  1.5604e-03,  3.8677e-02, -6.2487e-02, -1.1674e-02,\n",
              "                       1.0230e-01, -1.7456e-02,  5.8576e-03,  6.4307e-02, -6.2232e-02,\n",
              "                      -1.7097e-01,  1.6831e-02, -9.1085e-02, -9.2858e-02, -1.7098e-02,\n",
              "                      -2.1640e-01, -3.0497e-02,  7.2440e-03, -4.7935e-02, -2.6186e-04,\n",
              "                       4.7071e-02, -5.5143e-02, -1.7737e-01, -4.5757e-03, -1.4190e-01,\n",
              "                      -5.1157e-02, -1.8956e-03, -2.1213e-01, -3.6720e-02,  7.1196e-02,\n",
              "                      -4.1082e-02, -3.9499e-03,  2.1465e-02, -6.8209e-02, -1.5377e-01,\n",
              "                       2.8674e-03, -1.0723e-01, -1.0083e-01,  1.2268e-02, -2.1920e-01,\n",
              "                       1.6225e-01,  1.2471e-01,  1.0322e-01,  1.1925e-02,  1.6196e-01,\n",
              "                       3.6649e-02,  1.5555e-01,  4.2193e-02,  1.1351e-01, -2.4981e-02,\n",
              "                       2.3644e-01,  1.3634e-02])),\n",
              "             ('batch_norm0.running_mean',\n",
              "              tensor([ 8.8148e-03,  3.3016e-01,  4.1325e-01,  2.6171e-03,  2.3693e-03,\n",
              "                      -1.2401e-02, -1.9701e-02,  4.3925e-02,  3.6122e-02,  1.7338e-01,\n",
              "                       2.0869e-01,  6.6652e-02,  6.0792e-02,  9.5008e-02,  1.0155e-01,\n",
              "                       1.6118e-01,  1.7528e-01,  1.1976e-01,  1.2266e-01,  2.7179e-01,\n",
              "                       2.6629e-01,  1.7148e-01,  1.8024e-01,  2.2954e-01,  2.3276e-01,\n",
              "                       2.6955e-01,  2.6771e-01,  1.2275e-01,  1.5956e-01,  2.9195e-01,\n",
              "                       3.3732e-01,  2.0051e-01,  2.4798e-01,  2.7928e-01,  3.3081e-01,\n",
              "                       3.0347e-01,  3.5783e-01,  2.8163e-02,  2.3247e-02,  3.3342e-02,\n",
              "                       5.1286e-02,  4.4330e-01,  2.6332e-01,  9.7303e-02,  2.8572e-01,\n",
              "                       2.4123e-01,  3.5207e-01,  2.6082e-01,  4.6060e-01,  5.8979e-01,\n",
              "                       3.8312e-01,  4.7022e-01, -5.4479e-04,  2.5625e-01,  3.2556e-01,\n",
              "                       2.5206e-01,  4.3257e-01,  2.6011e-01,  2.6395e-01,  3.1768e-01,\n",
              "                       5.2708e-01,  5.3049e-01,  5.0135e-01,  4.9916e-01,  3.8342e-01,\n",
              "                       5.8342e-01,  5.8909e-01,  5.6317e-01,  5.6553e-01,  3.2429e-01,\n",
              "                       2.8073e-01,  3.8672e-01,  4.0725e-03, -3.3986e-02,  1.7525e-04,\n",
              "                      -1.6095e-02, -3.6724e-02, -6.1601e-02,  1.6354e-04, -2.9895e-02,\n",
              "                       2.4510e-03, -6.3917e-03, -3.1907e-02, -3.9591e-02,  4.0052e-01,\n",
              "                       6.0042e-01,  4.2005e-01,  4.8370e-01,  5.5267e-01,  3.8503e-01,\n",
              "                       2.7087e-01,  4.9819e-01,  3.1307e-01,  3.4146e-01,  3.9365e-01,\n",
              "                       2.3450e-01,  4.0415e-01,  6.0261e-01,  4.2646e-01,  4.6763e-01,\n",
              "                       5.3840e-01,  3.9352e-01,  2.3971e-01,  4.5816e-01,  3.2089e-01,\n",
              "                       3.4171e-01,  4.0511e-01,  2.2725e-01,  3.9552e-01,  5.1039e-01,\n",
              "                       4.2265e-01,  4.4832e-01,  4.9743e-01,  3.8023e-01,  2.5931e-01,\n",
              "                       3.4045e-01,  2.8585e-01,  3.0061e-01,  3.2862e-01,  2.6247e-01,\n",
              "                       2.4245e-01,  2.4854e-01,  2.4368e-01,  2.5858e-01,  2.4813e-01,\n",
              "                       2.2383e-01,  2.1301e-01,  2.1429e-01,  2.2987e-01,  2.2646e-01,\n",
              "                       8.0392e-01,  9.2062e-01])),\n",
              "             ('batch_norm0.running_var',\n",
              "              tensor([9.9996e-01, 6.4087e+00, 6.3724e+00, 3.3879e+00, 2.9767e+00, 2.6800e+00,\n",
              "                      2.7700e+00, 2.4036e+00, 3.4624e+00, 5.4656e+00, 3.0383e+00, 2.5538e+00,\n",
              "                      5.9912e+00, 4.8514e+00, 4.4279e+00, 3.3146e+00, 5.2154e+00, 2.2295e+00,\n",
              "                      4.1860e+00, 2.7367e+00, 3.9561e+00, 5.4781e+00, 3.6031e+00, 4.2828e+00,\n",
              "                      7.3668e+00, 4.0927e+00, 5.7340e+00, 1.7600e+00, 3.5861e+00, 2.7357e+00,\n",
              "                      4.5118e+00, 2.6210e+00, 6.4869e+00, 3.4778e+00, 4.4892e+00, 5.3525e+00,\n",
              "                      5.3529e+00, 3.6782e+00, 4.4150e+00, 2.2028e+00, 5.0443e+00, 4.2839e+00,\n",
              "                      5.6709e+00, 5.1625e+00, 7.9830e+00, 2.3305e+00, 4.4743e+00, 4.6555e+00,\n",
              "                      8.7651e+00, 1.3869e+01, 6.8012e+00, 7.1573e+00, 3.4492e+00, 4.4372e+00,\n",
              "                      3.6013e+00, 7.2891e+00, 2.3329e+01, 8.8914e+00, 1.1696e+01, 1.5590e+01,\n",
              "                      4.7898e+00, 3.8766e+00, 4.7512e+00, 5.1320e+00, 5.5516e+00, 4.6977e+00,\n",
              "                      3.0158e+00, 6.5997e+00, 6.2842e+00, 5.0679e+00, 6.1444e+00, 3.4047e+00,\n",
              "                      3.4769e+00, 4.9778e+00, 3.3107e+00, 4.1386e+00, 5.2649e+00, 7.4667e+00,\n",
              "                      4.2053e+00, 3.6834e+00, 2.9608e+00, 5.2554e+00, 4.3797e+00, 5.2137e+00,\n",
              "                      4.0137e+00, 6.6216e+00, 4.1544e+00, 7.6065e+00, 6.9990e+00, 7.2999e+00,\n",
              "                      3.9968e+00, 7.4646e+00, 3.9709e+00, 4.6986e+00, 4.4746e+00, 5.4025e+00,\n",
              "                      4.7350e+00, 6.9139e+00, 5.5672e+00, 4.8166e+00, 5.3830e+00, 7.2956e+00,\n",
              "                      5.0078e+00, 6.3748e+00, 3.2087e+00, 4.6941e+00, 8.9654e+00, 5.3320e+00,\n",
              "                      6.1981e+00, 6.8007e+00, 4.1283e+00, 4.1630e+00, 6.9133e+00, 8.7878e+00,\n",
              "                      4.0690e+00, 6.1291e+00, 5.0995e+00, 6.2812e+00, 6.2290e+00, 3.5665e+00,\n",
              "                      3.2607e+00, 4.4084e+00, 4.0845e+00, 3.8506e+00, 2.7220e+00, 4.8154e+00,\n",
              "                      6.0336e+00, 3.1275e+00, 5.0195e+00, 3.0586e+00, 1.4286e+01, 1.6129e+05])),\n",
              "             ('batch_norm0.num_batches_tracked', tensor(7296)),\n",
              "             ('dense1.weight',\n",
              "              tensor([[ 0.0027,  0.0847,  0.0921,  ..., -0.0466, -0.0105,  0.0165],\n",
              "                      [-0.0566, -0.0112,  0.0120,  ...,  0.0837,  0.0186, -0.0291],\n",
              "                      [-0.0460,  0.0119,  0.0405,  ..., -0.0172, -0.0170,  0.0165],\n",
              "                      ...,\n",
              "                      [ 0.0357,  0.0228, -0.0398,  ..., -0.0030,  0.0014, -0.0034],\n",
              "                      [ 0.0271, -0.0381, -0.0316,  ...,  0.0564, -0.0348, -0.0040],\n",
              "                      [-0.0298, -0.0233, -0.0128,  ...,  0.0440, -0.0833,  0.0126]])),\n",
              "             ('dense1.bias',\n",
              "              tensor([-1.3116e-06, -3.0194e-06, -9.1294e-07,  1.1003e-06, -3.3930e-07,\n",
              "                       2.5858e-06,  8.1859e-06, -4.6305e-06, -1.8346e-06,  1.0446e-05,\n",
              "                      -1.4011e-06, -4.3417e-07, -3.5880e-06,  8.7225e-07, -2.1578e-07,\n",
              "                       4.3288e-07, -1.4055e-06,  2.4908e-06, -7.7712e-06, -2.0494e-06,\n",
              "                      -5.2476e-08,  7.9600e-07, -1.1948e-06,  2.6423e-06, -4.7921e-07,\n",
              "                      -4.7728e-06, -7.5592e-07,  8.3125e-06,  4.3551e-06, -4.7312e-06,\n",
              "                       4.3311e-06,  1.1361e-06,  3.1042e-08,  2.0084e-06,  8.0650e-07,\n",
              "                      -1.6131e-06, -9.5284e-06, -7.0136e-06, -2.5781e-06,  1.5181e-05,\n",
              "                       3.3330e-06, -2.5705e-06, -2.2489e-07,  3.4723e-06, -5.1335e-07,\n",
              "                      -1.8880e-06,  1.5354e-06, -1.0343e-06, -6.7537e-09,  5.3120e-06,\n",
              "                      -2.8858e-07, -2.9086e-07,  3.7878e-06, -1.7474e-06,  1.0998e-07,\n",
              "                       2.2008e-06,  2.3464e-06,  1.2837e-06, -6.4664e-08, -3.2428e-06,\n",
              "                       5.1207e-07,  1.7625e-06,  9.1017e-06,  1.7827e-06, -1.6192e-06,\n",
              "                      -3.8386e-06,  7.2319e-06,  2.5827e-06,  7.4275e-07,  6.1923e-06,\n",
              "                       1.5267e-06, -3.1520e-08, -9.4421e-06, -2.5539e-06, -4.8392e-07,\n",
              "                       4.1907e-07, -4.0049e-07, -1.4092e-06, -1.7073e-06, -2.6147e-06,\n",
              "                      -3.8832e-06, -3.8356e-06,  3.0173e-06, -3.1125e-06,  1.8668e-06,\n",
              "                      -2.8108e-06,  1.0537e-07, -3.9857e-07, -3.2098e-06,  4.5701e-06,\n",
              "                      -6.1365e-06, -2.2267e-08,  8.4952e-07, -9.1858e-07,  5.2574e-07,\n",
              "                       2.5269e-06,  3.4411e-06,  3.9710e-07, -9.0237e-06,  5.4593e-06,\n",
              "                      -3.1284e-06, -1.0893e-08,  1.9141e-06, -8.3428e-07,  6.6072e-06,\n",
              "                      -6.9900e-06,  3.2388e-07, -5.7544e-07, -3.3560e-07,  1.2133e-06,\n",
              "                       1.3941e-06,  6.1015e-06, -6.7282e-07, -1.9042e-06, -8.6041e-07,\n",
              "                      -4.8531e-06,  1.3633e-05, -2.8965e-07,  3.7338e-06,  5.1073e-06,\n",
              "                       5.2970e-06, -3.6805e-06, -3.8653e-06, -2.3598e-08,  2.6972e-06,\n",
              "                       1.4435e-06, -3.4488e-06,  3.6565e-07,  1.7379e-06,  2.7735e-06,\n",
              "                       4.6330e-06,  2.7941e-06,  1.2277e-07, -1.9491e-05, -3.7970e-06,\n",
              "                       1.1395e-07,  1.9564e-07, -3.1878e-06,  2.1306e-06,  8.9643e-07,\n",
              "                       3.2299e-06, -7.5866e-07,  1.0331e-06,  4.7226e-07, -9.1996e-07,\n",
              "                      -1.4192e-06,  6.3859e-06,  3.5999e-07,  9.3692e-06,  3.1103e-06,\n",
              "                      -1.3803e-06,  1.8600e-06,  1.1284e-06,  3.5417e-07,  1.4058e-06,\n",
              "                       8.8791e-07, -5.4992e-07,  1.0353e-06,  4.2508e-06, -2.1132e-06,\n",
              "                       4.6909e-06, -6.0427e-06,  1.3432e-06, -2.1545e-06,  3.6889e-06,\n",
              "                       2.3836e-06,  2.6200e-06, -5.0796e-06,  1.7161e-07,  3.3064e-06,\n",
              "                       1.8685e-06, -5.9464e-06,  2.7252e-06, -2.0747e-06,  1.0628e-06,\n",
              "                      -9.9673e-07,  2.1846e-06, -5.8305e-06,  3.8817e-06, -7.6397e-06,\n",
              "                      -1.7238e-06, -8.6849e-07,  1.5139e-06,  8.2044e-07,  4.8625e-06,\n",
              "                      -3.4445e-07, -7.6114e-07, -2.0956e-06, -3.6192e-06, -1.2919e-06,\n",
              "                       4.8737e-07,  3.6549e-06,  1.8740e-06, -3.0357e-06,  2.6752e-07,\n",
              "                      -1.8408e-06, -2.5170e-06,  8.1721e-06,  5.8327e-07, -2.0493e-06,\n",
              "                       3.2026e-06,  4.3290e-07, -6.5705e-08, -9.5434e-07,  1.0267e-06,\n",
              "                       1.4275e-06,  6.1529e-06, -1.9897e-06, -6.7575e-07,  2.6186e-06,\n",
              "                       2.3432e-06,  4.0959e-06, -3.7229e-07,  3.5085e-06,  4.3980e-06,\n",
              "                       6.5239e-07, -6.9328e-07, -1.0863e-06, -4.8909e-06,  1.8850e-07,\n",
              "                       1.0362e-06,  1.4284e-06, -1.3607e-06, -1.3340e-06,  8.5666e-09,\n",
              "                      -5.4724e-07, -2.6964e-06, -3.1808e-06, -5.9542e-06, -2.1089e-06,\n",
              "                      -6.7147e-06, -4.7378e-06,  3.1895e-07, -2.5114e-06,  4.4298e-06,\n",
              "                       4.1832e-06,  1.9877e-06,  1.3184e-06,  9.3664e-06,  1.9259e-06,\n",
              "                       5.8744e-06, -2.2657e-06,  2.0910e-06,  1.3812e-06,  2.0107e-06,\n",
              "                       5.6710e-07,  5.6936e-06, -4.0790e-06,  3.9076e-06, -3.1087e-06,\n",
              "                      -2.9527e-06, -4.1521e-07,  1.3579e-06, -4.1347e-07,  6.6994e-07,\n",
              "                      -2.5831e-06])),\n",
              "             ('batch_norm1.weight',\n",
              "              tensor([0.2627, 0.2586, 0.2621, 0.2275, 0.2986, 0.2975, 0.2732, 0.2778, 0.2420,\n",
              "                      0.1894, 0.2598, 0.2302, 0.2087, 0.2776, 0.2360, 0.2232, 0.2766, 0.2661,\n",
              "                      0.3134, 0.1644, 0.2548, 0.2236, 0.2436, 0.2062, 0.3150, 0.2325, 0.2345,\n",
              "                      0.2701, 0.2584, 0.1856, 0.2107, 0.3376, 0.2489, 0.2359, 0.2214, 0.2081,\n",
              "                      0.2619, 0.2256, 0.2666, 0.2644, 0.2129, 0.2248, 0.1674, 0.2502, 0.3245,\n",
              "                      0.2929, 0.2853, 0.1764, 0.2751, 0.1936, 0.2153, 0.2526, 0.1557, 0.2988,\n",
              "                      0.2744, 0.2260, 0.2854, 0.2784, 0.2961, 0.1984, 0.2831, 0.2636, 0.2688,\n",
              "                      0.2259, 0.2754, 0.2553, 0.2845, 0.2325, 0.1937, 0.2254, 0.2105, 0.2674,\n",
              "                      0.2809, 0.3027, 0.1916, 0.1935, 0.2688, 0.3185, 0.1752, 0.2423, 0.3316,\n",
              "                      0.3473, 0.2960, 0.3138, 0.1962, 0.3147, 0.2690, 0.2379, 0.2763, 0.2157,\n",
              "                      0.2987, 0.1911, 0.2502, 0.2240, 0.2511, 0.1872, 0.3253, 0.2185, 0.2791,\n",
              "                      0.3187, 0.1671, 0.2252, 0.2251, 0.1798, 0.2908, 0.2795, 0.2128, 0.2065,\n",
              "                      0.3155, 0.2922, 0.2535, 0.2904, 0.2555, 0.1964, 0.3514, 0.2939, 0.2574,\n",
              "                      0.2006, 0.2744, 0.3321, 0.2308, 0.1936, 0.2359, 0.2890, 0.3100, 0.2704,\n",
              "                      0.2649, 0.2327, 0.1690, 0.1588, 0.2933, 0.2591, 0.3052, 0.4402, 0.2997,\n",
              "                      0.2817, 0.2863, 0.3001, 0.2555, 0.2805, 0.2492, 0.2654, 0.3653, 0.1878,\n",
              "                      0.3052, 0.3865, 0.2239, 0.2272, 0.2763, 0.3583, 0.3223, 0.3211, 0.2294,\n",
              "                      0.2513, 0.2658, 0.2700, 0.3167, 0.2965, 0.2067, 0.2562, 0.2516, 0.2822,\n",
              "                      0.2226, 0.2560, 0.2315, 0.2868, 0.3310, 0.3728, 0.2714, 0.2716, 0.2210,\n",
              "                      0.2551, 0.2313, 0.2568, 0.2361, 0.3078, 0.2468, 0.2043, 0.2662, 0.2414,\n",
              "                      0.2020, 0.2603, 0.2006, 0.2522, 0.2251, 0.2662, 0.2671, 0.2341, 0.3011,\n",
              "                      0.3318, 0.2705, 0.3048, 0.2380, 0.3027, 0.2245, 0.2893, 0.2622, 0.2613,\n",
              "                      0.2185, 0.2742, 0.3135, 0.1793, 0.2335, 0.2503, 0.2646, 0.2624, 0.2821,\n",
              "                      0.2278, 0.1622, 0.2343, 0.2075, 0.2322, 0.2624, 0.3214, 0.2898, 0.2416,\n",
              "                      0.2903, 0.2382, 0.2066, 0.3602, 0.2403, 0.2371, 0.3215, 0.2215, 0.2828,\n",
              "                      0.2808, 0.2468, 0.2763, 0.2599, 0.2950, 0.2930, 0.2928, 0.2582, 0.3243,\n",
              "                      0.3166, 0.2717, 0.2523, 0.2408, 0.2608, 0.2051, 0.3631, 0.3579, 0.3078,\n",
              "                      0.2395, 0.2832, 0.2619, 0.2424, 0.3407, 0.2936, 0.2603, 0.3390, 0.2466,\n",
              "                      0.2216, 0.2415, 0.2632, 0.2530])),\n",
              "             ('batch_norm1.bias',\n",
              "              tensor([-0.1505, -0.1490, -0.2317, -0.2265, -0.1380, -0.1717, -0.3049, -0.1668,\n",
              "                      -0.2876, -0.1660, -0.2825, -0.1691, -0.1030, -0.1842, -0.0820, -0.2236,\n",
              "                      -0.2801, -0.0872, -0.1783, -0.3104, -0.2549, -0.1463, -0.0901, -0.1282,\n",
              "                      -0.1257, -0.1798, -0.1806, -0.2387, -0.1772, -0.2048, -0.2263, -0.3953,\n",
              "                      -0.2036, -0.1881, -0.2102, -0.1899, -0.2873, -0.2285, -0.2434, -0.3543,\n",
              "                      -0.1825, -0.2355, -0.1227, -0.3356, -0.2067, -0.2109, -0.1902, -0.1274,\n",
              "                      -0.3035, -0.2855, -0.1261, -0.2271, -0.0730, -0.2074, -0.2677, -0.2412,\n",
              "                      -0.2153, -0.2562, -0.1809, -0.2030, -0.1722, -0.1738, -0.2182, -0.2210,\n",
              "                      -0.2705, -0.3950, -0.1086, -0.2466, -0.2325, -0.1623, -0.1928, -0.2977,\n",
              "                      -0.3668, -0.2127, -0.1611, -0.2869, -0.2750, -0.3099, -0.1369, -0.2547,\n",
              "                      -0.2633, -0.1990, -0.1497, -0.3577, -0.2592, -0.2157, -0.3832, -0.1939,\n",
              "                      -0.1633, -0.3045, -0.2714, -0.1993, -0.2040, -0.1703, -0.2028, -0.1565,\n",
              "                      -0.2013, -0.2683, -0.2646, -0.3269, -0.0738, -0.2119, -0.1069, -0.1004,\n",
              "                      -0.1771, -0.0798, -0.1813, -0.1605, -0.2568, -0.3678, -0.1928, -0.2470,\n",
              "                      -0.1940, -0.0620, -0.3400, -0.2118, -0.1985, -0.3168, -0.1965, -0.1782,\n",
              "                      -0.1295, -0.2946, -0.2965, -0.2215, -0.1638, -0.1119, -0.2588, -0.1576,\n",
              "                      -0.2390, -0.2006, -0.2856, -0.2117, -0.2258, -0.5746, -0.1445, -0.1900,\n",
              "                      -0.2299, -0.3013, -0.2869, -0.1274, -0.2401, -0.2733, -0.2276, -0.1768,\n",
              "                      -0.1795, -0.2827, -0.1687, -0.2296, -0.2433, -0.2272, -0.2624, -0.2233,\n",
              "                      -0.2215, -0.2962, -0.2329, -0.1455, -0.1679, -0.2617, -0.1861, -0.2769,\n",
              "                      -0.2388, -0.2044, -0.1059, -0.3323, -0.1279, -0.1949, -0.1884, -0.2072,\n",
              "                      -0.3045, -0.2157, -0.1281, -0.1807, -0.2097, -0.2017, -0.2698, -0.1231,\n",
              "                      -0.1681, -0.1259, -0.1821, -0.1601, -0.1049, -0.1319, -0.2445, -0.1857,\n",
              "                      -0.0706, -0.2630, -0.2123, -0.2089, -0.2440, -0.3727, -0.1507, -0.1486,\n",
              "                      -0.3063, -0.3159, -0.2584, -0.2371, -0.2677, -0.2079, -0.3218, -0.2032,\n",
              "                      -0.2479, -0.2097, -0.2132, -0.1178, -0.0372, -0.1781, -0.1188, -0.3154,\n",
              "                      -0.1249, -0.3296, -0.1137, -0.1666, -0.2601, -0.2017, -0.1508, -0.2350,\n",
              "                      -0.2532, -0.1647, -0.2158, -0.3559, -0.1538, -0.1020, -0.2675, -0.1248,\n",
              "                      -0.2405, -0.1563, -0.1698, -0.1390, -0.1996, -0.1350, -0.3721, -0.3449,\n",
              "                      -0.2407, -0.1860, -0.1835, -0.1701, -0.3001, -0.1037, -0.1140, -0.1901,\n",
              "                      -0.4338, -0.2642, -0.2546, -0.3003, -0.2455, -0.1994, -0.1788, -0.2024,\n",
              "                      -0.2516, -0.1772, -0.1402, -0.1814, -0.2185, -0.1610, -0.2045, -0.1801])),\n",
              "             ('batch_norm1.running_mean',\n",
              "              tensor([ 2.7345e-02, -1.0608e-01, -6.3368e-02, -2.3176e-02,  1.1185e-01,\n",
              "                       4.2127e-02, -3.1895e-01,  4.5514e-02, -2.3773e-02,  1.0815e-01,\n",
              "                       2.0869e-03,  8.0892e-02,  1.7111e-01, -5.4433e-02,  7.0255e-02,\n",
              "                       3.0645e-02,  2.7561e-01,  4.5507e-02,  1.2647e-01, -2.1087e-01,\n",
              "                      -1.2422e-01,  1.0526e-01,  5.2781e-02,  2.0079e-02,  2.4337e-01,\n",
              "                      -1.1431e-01,  2.9000e-02,  1.2433e-01, -8.4574e-02, -3.8327e-02,\n",
              "                      -1.4717e-01,  1.9622e-03,  3.3972e-02,  3.9828e-02,  2.3089e-02,\n",
              "                      -1.3165e-02, -3.0416e-01, -5.9610e-02,  1.8462e-01, -2.3286e-01,\n",
              "                       1.8203e-01, -6.4435e-02, -5.3884e-02,  8.0191e-02,  1.0704e-03,\n",
              "                       3.5999e-02, -1.2995e-01,  1.4806e-01, -4.0955e-02, -1.6283e-01,\n",
              "                      -3.3121e-02,  2.5128e-02,  5.1273e-02, -7.7207e-02,  1.2525e-01,\n",
              "                      -3.9600e-02,  1.6562e-01, -4.5648e-02, -1.4176e-02, -4.6313e-02,\n",
              "                       9.3757e-03,  3.3512e-02,  1.1482e-01, -1.3387e-02, -7.7298e-02,\n",
              "                      -4.1616e-02,  2.2850e-01, -1.2257e-04, -8.1495e-03, -1.7229e-01,\n",
              "                       5.4679e-02,  4.2742e-02, -3.0406e-01,  1.6690e-01,  2.4239e-02,\n",
              "                       2.1347e-02, -1.4468e-01,  2.2301e-02,  7.6559e-02,  2.2649e-02,\n",
              "                      -1.1025e-02, -2.3605e-01,  7.3701e-02, -2.1865e-01, -3.4332e-02,\n",
              "                      -9.4581e-02, -4.5867e-02, -7.0523e-03, -1.4297e-02, -1.3320e-01,\n",
              "                       1.3426e-01,  6.8874e-02,  7.2445e-02, -9.9899e-03, -8.7043e-03,\n",
              "                      -7.6416e-02,  5.6047e-02,  2.6631e-02,  1.0899e-01, -1.8781e-01,\n",
              "                       1.6006e-01,  2.8594e-02,  7.6630e-02, -8.5230e-02,  1.1393e-01,\n",
              "                       2.6333e-01, -3.2995e-02, -2.9587e-02,  1.4296e-01, -3.2925e-01,\n",
              "                       1.3133e-02,  1.1204e-01,  2.2617e-02, -4.9935e-02, -9.5778e-02,\n",
              "                       1.4407e-01,  2.0106e-01, -2.5836e-02, -5.8078e-02,  6.2028e-02,\n",
              "                       4.0609e-02,  3.6024e-02, -1.4134e-01,  6.4460e-02, -1.4519e-01,\n",
              "                       7.8440e-02,  9.0181e-02,  4.7028e-02, -8.2187e-02, -2.3849e-01,\n",
              "                       4.1151e-02,  9.3256e-02, -8.0240e-02, -4.9740e-01,  5.4379e-02,\n",
              "                       1.7801e-01,  8.9694e-02, -1.4847e-01, -9.6967e-02,  4.9383e-02,\n",
              "                      -1.2036e-01, -1.7324e-01, -3.3650e-02,  7.9283e-02,  9.2385e-03,\n",
              "                       1.2667e-01,  8.6575e-02, -5.6913e-02, -1.8370e-01,  1.3896e-02,\n",
              "                      -7.5691e-02, -5.8975e-02,  1.8014e-02,  1.7391e-02, -1.9281e-02,\n",
              "                       8.4826e-03,  1.0942e-01,  2.7712e-02, -1.1118e-01, -2.8470e-02,\n",
              "                      -6.3850e-02,  1.4559e-01,  1.4343e-01, -2.6570e-01,  1.1751e-01,\n",
              "                       7.4898e-02,  1.0971e-02, -1.1228e-01, -6.9191e-02, -2.2004e-01,\n",
              "                       4.6452e-03,  1.3919e-01,  8.9613e-03, -1.0884e-01, -3.3264e-03,\n",
              "                       1.0407e-01,  3.1124e-02, -8.5695e-02,  6.0446e-02,  8.7756e-02,\n",
              "                       1.1761e-03,  1.0611e-02, -1.2188e-01,  1.0047e-01,  6.4952e-02,\n",
              "                      -1.4942e-02, -4.6328e-02,  1.1337e-01,  2.0758e-02, -1.0685e-01,\n",
              "                       1.1074e-01,  3.6860e-02, -2.7612e-02, -8.3707e-02, -2.2743e-01,\n",
              "                       6.9425e-02, -1.1373e-01,  5.4499e-02, -2.4817e-02,  4.3666e-02,\n",
              "                      -1.7886e-01,  6.5504e-02, -2.3754e-02,  8.0232e-03,  1.9933e-02,\n",
              "                       4.3802e-02,  2.5298e-02,  2.5617e-02,  9.9526e-04, -9.6037e-02,\n",
              "                       2.0851e-01, -4.6103e-02,  9.0695e-02, -8.8576e-02,  1.5318e-01,\n",
              "                      -2.4501e-02,  8.0034e-02,  3.9642e-02, -1.6670e-01, -5.1638e-02,\n",
              "                       1.9994e-02,  1.5138e-01,  2.1481e-01,  8.1411e-02,  2.1360e-02,\n",
              "                      -1.3617e-01, -6.5131e-02,  7.2817e-02, -8.1347e-02,  3.5580e-02,\n",
              "                      -3.5373e-01, -5.0855e-02, -8.6851e-03,  1.1489e-01,  2.8877e-07,\n",
              "                       1.7276e-01,  3.3526e-02,  6.4312e-02,  2.7797e-01,  6.5679e-02,\n",
              "                      -3.8174e-01,  4.9837e-02, -1.1901e-01, -2.9286e-01,  1.3036e-01,\n",
              "                      -3.9732e-02, -9.6757e-02, -2.7720e-03, -7.4892e-02, -7.0396e-02,\n",
              "                       1.1106e-02, -1.4144e-01,  1.1903e-01,  1.0060e-01,  1.2012e-03,\n",
              "                       1.9241e-01])),\n",
              "             ('batch_norm1.running_var',\n",
              "              tensor([0.1512, 0.2555, 0.2476, 0.1835, 0.2093, 0.3658, 0.3495, 0.1586, 0.2253,\n",
              "                      0.1557, 0.1894, 0.1671, 0.1429, 0.2511, 0.2494, 0.1619, 0.2257, 0.1704,\n",
              "                      0.3144, 0.1812, 0.3079, 0.1336, 0.2066, 0.1872, 0.2791, 0.2135, 0.1499,\n",
              "                      0.1626, 0.2729, 0.1857, 0.1733, 0.2069, 0.1573, 0.1387, 0.1526, 0.1364,\n",
              "                      0.3364, 0.2064, 0.2396, 0.2308, 0.2524, 0.2083, 0.1753, 0.2014, 0.3038,\n",
              "                      0.3180, 0.2560, 0.1423, 0.2071, 0.1919, 0.1695, 0.1503, 0.1753, 0.2553,\n",
              "                      0.1769, 0.1443, 0.1377, 0.2029, 0.2204, 0.1433, 0.2129, 0.1858, 0.1605,\n",
              "                      0.1444, 0.2091, 0.1446, 0.2469, 0.1830, 0.1220, 0.1862, 0.1675, 0.2030,\n",
              "                      0.3522, 0.2317, 0.1043, 0.1639, 0.2955, 0.2396, 0.0967, 0.1329, 0.1936,\n",
              "                      0.3251, 0.1916, 0.2484, 0.1418, 0.3045, 0.2268, 0.1419, 0.1905, 0.2354,\n",
              "                      0.3492, 0.1332, 0.1857, 0.2018, 0.2114, 0.2168, 0.1957, 0.2115, 0.3151,\n",
              "                      0.3567, 0.1607, 0.1703, 0.1739, 0.1373, 0.2508, 0.2750, 0.1454, 0.2502,\n",
              "                      0.3416, 0.2806, 0.1656, 0.1466, 0.1565, 0.1737, 0.2845, 0.1988, 0.1287,\n",
              "                      0.1370, 0.1717, 0.3630, 0.2125, 0.1666, 0.1728, 0.1654, 0.3603, 0.1576,\n",
              "                      0.1680, 0.1671, 0.1187, 0.1781, 0.3213, 0.2547, 0.2594, 0.4292, 0.2595,\n",
              "                      0.2679, 0.1257, 0.2164, 0.1838, 0.1807, 0.2002, 0.3312, 0.2443, 0.1623,\n",
              "                      0.3432, 0.2304, 0.0996, 0.1553, 0.2787, 0.2753, 0.2182, 0.2547, 0.2493,\n",
              "                      0.2407, 0.1707, 0.1685, 0.2384, 0.1889, 0.1588, 0.1492, 0.1506, 0.2717,\n",
              "                      0.2059, 0.3783, 0.2010, 0.2775, 0.2892, 0.3794, 0.2802, 0.3560, 0.1791,\n",
              "                      0.1888, 0.1078, 0.1993, 0.1190, 0.2948, 0.2297, 0.2053, 0.1770, 0.1036,\n",
              "                      0.2270, 0.2228, 0.2234, 0.1783, 0.2292, 0.1502, 0.2038, 0.1975, 0.2156,\n",
              "                      0.2278, 0.2131, 0.2102, 0.1349, 0.2875, 0.2585, 0.2247, 0.2399, 0.2139,\n",
              "                      0.1641, 0.1754, 0.2997, 0.2101, 0.1680, 0.2240, 0.2769, 0.1699, 0.1832,\n",
              "                      0.1889, 0.1145, 0.2118, 0.2079, 0.2195, 0.2112, 0.3066, 0.2372, 0.2249,\n",
              "                      0.1758, 0.3043, 0.2539, 0.3049, 0.1893, 0.2379, 0.2796, 0.2250, 0.1765,\n",
              "                      0.3489, 0.1726, 0.2853, 0.2011, 0.2032, 0.2776, 0.2333, 0.2844, 0.1550,\n",
              "                      0.2790, 0.2052, 0.2413, 0.1665, 0.2338, 0.1500, 0.3397, 0.3048, 0.2190,\n",
              "                      0.2304, 0.1541, 0.2478, 0.2746, 0.2926, 0.3050, 0.2038, 0.3649, 0.3013,\n",
              "                      0.1539, 0.2047, 0.1813, 0.2247])),\n",
              "             ('batch_norm1.num_batches_tracked', tensor(7296)),\n",
              "             ('dense2.weight',\n",
              "              tensor([[-0.0223, -0.0407,  0.0183,  ..., -0.0593, -0.0475, -0.0437],\n",
              "                      [-0.0127, -0.0350, -0.0023,  ..., -0.0299,  0.0040, -0.0358],\n",
              "                      [ 0.0754,  0.1168,  0.1465,  ...,  0.0252, -0.0096,  0.0288],\n",
              "                      ...,\n",
              "                      [ 0.0132, -0.0624,  0.0150,  ...,  0.0088,  0.0154, -0.0350],\n",
              "                      [-0.0097, -0.0929, -0.1589,  ..., -0.0277, -0.0233, -0.0173],\n",
              "                      [-0.0284, -0.0852, -0.1130,  ..., -0.0218, -0.0476, -0.0466]])),\n",
              "             ('dense2.bias',\n",
              "              tensor([ 2.8616e-06,  6.1338e-06,  1.5288e-05,  8.4347e-06, -3.2204e-07,\n",
              "                      -4.9400e-08, -2.8664e-06,  6.9242e-06, -1.0960e-06,  4.4385e-06,\n",
              "                       8.7507e-07,  7.0822e-06,  1.7423e-06, -1.7056e-05, -8.0753e-07,\n",
              "                       6.2531e-07,  5.0998e-07,  8.1824e-07,  8.9743e-07, -1.7191e-06,\n",
              "                      -1.1169e-05,  4.1821e-06, -5.9270e-05,  1.4372e-06, -3.4463e-07,\n",
              "                       3.8253e-07,  1.3063e-06, -2.3214e-06,  2.1380e-06,  2.5871e-05,\n",
              "                       2.4742e-05,  3.9757e-07, -6.5443e-06,  1.4365e-05, -2.9583e-07,\n",
              "                       1.5442e-06, -2.2438e-06,  6.7077e-06, -1.7827e-06, -3.3499e-06,\n",
              "                      -9.0791e-06,  7.5118e-06,  3.6989e-06, -5.0421e-07, -7.2986e-06,\n",
              "                      -1.8771e-06, -7.4724e-07, -6.9171e-07, -1.3826e-06,  1.3624e-07,\n",
              "                      -2.6571e-06, -2.8423e-06, -6.9002e-06,  4.2041e-06, -2.8160e-06,\n",
              "                       1.6795e-05,  4.4967e-06, -3.6630e-06,  6.7381e-06, -5.3449e-06,\n",
              "                      -4.3448e-06, -2.4672e-06,  2.0396e-06,  5.8832e-06,  3.3884e-06,\n",
              "                       5.2277e-06, -7.3526e-06,  3.4680e-06,  3.2407e-06, -1.9851e-06,\n",
              "                       5.0491e-06, -5.7467e-06,  2.2747e-06,  2.6981e-06,  3.6832e-07,\n",
              "                       9.9872e-07, -1.3330e-05, -2.3369e-06, -1.0714e-05, -3.0068e-05,\n",
              "                       2.3727e-07,  2.9831e-07, -2.4332e-06, -1.9793e-05,  7.5919e-06,\n",
              "                      -3.5211e-08, -1.1822e-06, -1.1858e-06,  3.8358e-07,  9.8452e-07,\n",
              "                      -1.8590e-06,  4.1804e-06,  3.6602e-05, -9.4306e-06, -4.1507e-06,\n",
              "                       6.9438e-06,  1.0641e-05, -2.5016e-07, -2.7750e-06,  3.7639e-06,\n",
              "                       5.6567e-06,  1.1259e-05, -1.4016e-05,  2.6138e-06,  7.7745e-05,\n",
              "                      -9.9644e-07,  9.7651e-06, -6.2707e-06, -1.1584e-05,  1.4631e-05,\n",
              "                      -2.0615e-06, -6.5774e-07, -2.7829e-06,  1.0814e-06,  6.2716e-07,\n",
              "                       3.1285e-06, -1.3406e-05,  1.6804e-06, -5.1613e-06,  1.4026e-06,\n",
              "                       4.6179e-06,  7.7209e-06,  1.8201e-05, -1.5940e-06,  1.8629e-06,\n",
              "                      -3.3950e-06,  5.0218e-07, -1.2207e-06, -1.1008e-05, -4.4026e-06,\n",
              "                      -1.1853e-06,  4.2306e-06,  1.2342e-06, -6.9621e-06, -7.9129e-06,\n",
              "                       8.6488e-07, -7.4239e-07, -5.6246e-07, -9.3484e-06, -1.3479e-06,\n",
              "                       4.5193e-06, -3.1714e-06,  1.6851e-06, -8.4952e-06,  1.8684e-06,\n",
              "                      -4.2781e-07,  4.0302e-06, -2.4416e-07,  2.2765e-06, -1.8143e-05,\n",
              "                       6.1012e-07,  2.8802e-06,  6.9187e-06, -4.4418e-07, -7.2419e-06,\n",
              "                      -4.6044e-06,  3.1094e-06, -2.9526e-06,  4.7482e-06,  7.1233e-07,\n",
              "                       1.7466e-07,  1.0522e-06, -5.7706e-06,  1.3121e-05,  1.7077e-06,\n",
              "                       4.6380e-06,  3.6794e-08, -9.6022e-07,  7.6589e-07,  8.7928e-06,\n",
              "                       8.4695e-06,  7.3009e-06, -1.4310e-06,  9.7592e-06,  7.8423e-06,\n",
              "                      -1.4101e-06,  7.7476e-06, -1.8309e-06, -7.5460e-06, -3.7378e-06,\n",
              "                      -1.0082e-06, -2.0883e-06,  4.3364e-06,  6.4189e-07, -1.5902e-06,\n",
              "                       3.7752e-06,  1.7801e-05,  8.8283e-07,  6.1613e-07,  6.5771e-06,\n",
              "                      -1.0954e-06,  8.1520e-06,  4.1513e-06,  6.5812e-06, -1.6884e-06,\n",
              "                       8.3006e-06, -7.7612e-07, -2.6814e-05, -2.8576e-06,  8.1994e-07,\n",
              "                       8.3983e-06,  1.4882e-05, -7.9711e-07, -2.4612e-06,  4.4540e-07,\n",
              "                       1.0287e-06, -2.4587e-06,  4.7053e-07, -3.6922e-06, -1.7348e-05,\n",
              "                       6.7049e-06, -1.7963e-05,  1.4644e-06, -1.2754e-06,  9.5800e-06,\n",
              "                       9.3445e-07,  6.9663e-08,  4.1641e-06, -4.1731e-07, -7.1342e-06,\n",
              "                       5.8398e-06,  5.3263e-06,  2.2190e-06, -2.0311e-06,  1.2090e-06,\n",
              "                      -1.9672e-05,  4.3667e-07, -4.4308e-06,  1.3534e-06, -1.5328e-06,\n",
              "                       5.0360e-06, -9.2405e-06, -4.5716e-06, -1.5744e-06, -4.5065e-07,\n",
              "                       3.4966e-07, -3.1394e-06,  2.1854e-07,  4.6217e-06,  1.6281e-05,\n",
              "                       4.6297e-06,  1.4698e-05,  1.6790e-05,  1.3368e-06, -2.2607e-05,\n",
              "                       5.1756e-06, -1.9498e-06, -8.7992e-06, -1.0999e-06, -7.3915e-06,\n",
              "                      -5.3929e-07, -1.1453e-06,  6.1763e-06,  7.8716e-06, -4.9445e-06,\n",
              "                      -3.7214e-06])),\n",
              "             ('batch_norm2.weight',\n",
              "              tensor([0.2376, 0.2077, 0.2019, 0.2163, 0.0542, 0.2432, 0.2453, 0.2329, 0.2125,\n",
              "                      0.2751, 0.2187, 0.1939, 0.2519, 0.1957, 0.1728, 0.2044, 0.2043, 0.2069,\n",
              "                      0.2697, 0.2935, 0.2038, 0.1909, 0.2185, 0.2108, 0.2014, 0.2888, 0.2271,\n",
              "                      0.2114, 0.2124, 0.2073, 0.2390, 0.2122, 0.2484, 0.2587, 0.2028, 0.1935,\n",
              "                      0.2122, 0.2735, 0.2047, 0.2611, 0.1931, 0.2191, 0.2102, 0.2234, 0.2591,\n",
              "                      0.2267, 0.2346, 0.2130, 0.2542, 0.2368, 0.2630, 0.2622, 0.2540, 0.2164,\n",
              "                      0.2344, 0.2263, 0.2606, 0.2502, 0.3071, 0.2210, 0.2685, 0.1850, 0.1936,\n",
              "                      0.2342, 0.2000, 0.1832, 0.2911, 0.2251, 0.1921, 0.2019, 0.2107, 0.2617,\n",
              "                      0.2475, 0.2164, 0.1664, 0.2150, 0.2152, 0.2316, 0.2466, 0.2788, 0.1812,\n",
              "                      0.2096, 0.2379, 0.1910, 0.1777, 0.2171, 0.2630, 0.2272, 0.2701, 0.2102,\n",
              "                      0.2145, 0.2301, 0.2362, 0.1734, 0.2675, 0.1463, 0.2387, 0.2187, 0.2483,\n",
              "                      0.2232, 0.2108, 0.1661, 0.2232, 0.2202, 0.2502, 0.2539, 0.1999, 0.2431,\n",
              "                      0.1796, 0.2416, 0.2456, 0.2251, 0.2324, 0.1706, 0.3092, 0.2297, 0.2251,\n",
              "                      0.1974, 0.2573, 0.1847, 0.2055, 0.1356, 0.2544, 0.2995, 0.2302, 0.1930,\n",
              "                      0.2519, 0.2398, 0.1756, 0.2224, 0.1486, 0.2518, 0.2059, 0.2249, 0.2199,\n",
              "                      0.1569, 0.2320, 0.2137, 0.1872, 0.2118, 0.2707, 0.2617, 0.2650, 0.2462,\n",
              "                      0.2324, 0.1685, 0.1924, 0.1781, 0.2626, 0.1694, 0.2828, 0.2083, 0.2312,\n",
              "                      0.2263, 0.1860, 0.2700, 0.2956, 0.2235, 0.2433, 0.2479, 0.2379, 0.2230,\n",
              "                      0.2439, 0.2764, 0.2794, 0.2211, 0.2600, 0.2299, 0.2694, 0.1943, 0.2202,\n",
              "                      0.2417, 0.2175, 0.1880, 0.2839, 0.1908, 0.1898, 0.1746, 0.2083, 0.2723,\n",
              "                      0.2545, 0.2332, 0.2177, 0.1602, 0.2720, 0.2193, 0.1612, 0.1690, 0.2328,\n",
              "                      0.2334, 0.2546, 0.2108, 0.2043, 0.1838, 0.2521, 0.2072, 0.2838, 0.2389,\n",
              "                      0.2374, 0.2945, 0.1825, 0.2147, 0.2520, 0.2153, 0.1521, 0.2382, 0.2295,\n",
              "                      0.2702, 0.1638, 0.2732, 0.2544, 0.2219, 0.2001, 0.1975, 0.2369, 0.1987,\n",
              "                      0.3128, 0.2529, 0.2329, 0.2551, 0.1868, 0.2249, 0.1840, 0.2448, 0.2915,\n",
              "                      0.2331, 0.2882, 0.1902, 0.2819, 0.2097, 0.2051, 0.2028, 0.2035, 0.2333,\n",
              "                      0.2479, 0.1886, 0.2412, 0.2105, 0.1895, 0.2341, 0.1977, 0.2186, 0.1845,\n",
              "                      0.2401, 0.3236, 0.2461, 0.2104, 0.2759, 0.2599, 0.1980, 0.2709, 0.2473,\n",
              "                      0.2332, 0.2555, 0.2082, 0.1895])),\n",
              "             ('batch_norm2.bias',\n",
              "              tensor([-0.2589, -0.1348, -0.1471, -0.1823, -0.1092, -0.2177, -0.2552, -0.1505,\n",
              "                      -0.1917, -0.2582, -0.2157, -0.0816, -0.1682, -0.2746, -0.1562, -0.3185,\n",
              "                      -0.2251, -0.1563, -0.2827, -0.2864, -0.1153, -0.1038, -0.2911, -0.2374,\n",
              "                      -0.1997, -0.3229, -0.3320, -0.1016, -0.2692, -0.2190, -0.2738, -0.2358,\n",
              "                      -0.3162, -0.3018, -0.1783, -0.1855, -0.2171, -0.3465, -0.0868, -0.2580,\n",
              "                      -0.2706, -0.2680, -0.1968, -0.2153, -0.1745, -0.1353, -0.2515, -0.2159,\n",
              "                      -0.2781, -0.2771, -0.2510, -0.1783, -0.1294, -0.4002, -0.1657, -0.2769,\n",
              "                      -0.2027, -0.2084, -0.2236, -0.2646, -0.3134, -0.2043, -0.1611, -0.1725,\n",
              "                      -0.2367, -0.1426, -0.2727, -0.1504, -0.0359, -0.2843, -0.2137, -0.2440,\n",
              "                      -0.1871, -0.1353, -0.1211, -0.2223, -0.1451, -0.1557, -0.2656, -0.3269,\n",
              "                      -0.2313, -0.2164, -0.3697, -0.1502, -0.1720, -0.0807, -0.2040, -0.1976,\n",
              "                      -0.2586, -0.4276, -0.2034, -0.3161, -0.2040, -0.2644, -0.3237, -0.1440,\n",
              "                      -0.2279, -0.1996, -0.2126, -0.2325, -0.1910, -0.2499, -0.2418, -0.2577,\n",
              "                      -0.2500, -0.1896, -0.1824, -0.2253, -0.1773, -0.2485, -0.2123, -0.1597,\n",
              "                      -0.3163, -0.1778, -0.2924, -0.2356, -0.4932, -0.1390, -0.1033, -0.1824,\n",
              "                      -0.2133, -0.0680, -0.2397, -0.1906, -0.2367, -0.1634, -0.1918, -0.3233,\n",
              "                      -0.2999, -0.2210, -0.1392, -0.1880, -0.1622, -0.1904, -0.1603, -0.1274,\n",
              "                      -0.1565, -0.3055, -0.1700, -0.3002, -0.3240, -0.2006, -0.2932, -0.3091,\n",
              "                      -0.1917, -0.1982, -0.1103, -0.2134, -0.1442, -0.1267, -0.1964, -0.1119,\n",
              "                      -0.2294, -0.2570, -0.2049, -0.1373, -0.2521, -0.2362, -0.1872, -0.2855,\n",
              "                      -0.2729, -0.2249, -0.1638, -0.3030, -0.4018, -0.3247, -0.2984, -0.2253,\n",
              "                      -0.2380, -0.1815, -0.2189, -0.2319, -0.0889, -0.2668, -0.1309, -0.1835,\n",
              "                      -0.1144, -0.2767, -0.2233, -0.1686, -0.1054, -0.2839, -0.1495, -0.3033,\n",
              "                      -0.3402, -0.2592, -0.2793, -0.2597, -0.2536, -0.1831, -0.2848, -0.2349,\n",
              "                      -0.1471, -0.1504, -0.2815, -0.1847, -0.1822, -0.2692, -0.1871, -0.4004,\n",
              "                      -0.1872, -0.2389, -0.1684, -0.2073, -0.1406, -0.2350, -0.1190, -0.3229,\n",
              "                      -0.2193, -0.2632, -0.2809, -0.2163, -0.2657, -0.1436, -0.3356, -0.1365,\n",
              "                      -0.1672, -0.3228, -0.1873, -0.2602, -0.2781, -0.1965, -0.1093, -0.2313,\n",
              "                      -0.1819, -0.2095, -0.3266, -0.2090, -0.2353, -0.3232, -0.0760, -0.1994,\n",
              "                      -0.2066, -0.1798, -0.3143, -0.2493, -0.1671, -0.2696, -0.1472, -0.2851,\n",
              "                      -0.3312, -0.3248, -0.2460, -0.1983, -0.4205, -0.1370, -0.1971, -0.2180,\n",
              "                      -0.4153, -0.3086, -0.2141, -0.1726, -0.2937, -0.3444, -0.1570, -0.1070])),\n",
              "             ('batch_norm2.running_mean',\n",
              "              tensor([-1.8160e-01, -4.8745e-02,  5.5349e-03,  6.3922e-02,  6.7203e-02,\n",
              "                       4.7756e-02, -1.3783e-01, -1.6562e-01, -2.1178e-02, -7.9914e-02,\n",
              "                      -5.1736e-02,  7.2129e-02,  3.7896e-02, -2.2316e-01,  2.2319e-02,\n",
              "                       1.2667e-02, -4.5615e-02, -1.4818e-01, -4.2646e-02, -1.7523e-01,\n",
              "                       9.6732e-02,  1.4649e-01, -3.1884e-01, -7.0806e-02,  2.6679e-02,\n",
              "                      -1.2558e-01, -1.4866e-01,  4.8634e-02, -2.0640e-01, -2.2155e-01,\n",
              "                      -1.8368e-01, -8.6134e-02, -3.3477e-01, -2.1081e-01, -1.6176e-01,\n",
              "                       5.7609e-02, -1.3403e-02, -2.3383e-01, -9.7561e-03,  3.1679e-02,\n",
              "                      -1.5335e-01, -1.2043e-01,  2.1242e-02, -7.9443e-02,  4.7423e-02,\n",
              "                      -7.8099e-02, -3.0077e-01,  1.2876e-02,  2.7895e-02, -1.1087e-01,\n",
              "                       2.3025e-01,  6.4213e-02, -6.2360e-02, -1.1896e-01,  5.8018e-02,\n",
              "                      -2.7414e-01, -6.9093e-02, -2.5615e-02, -3.5457e-01, -1.9809e-02,\n",
              "                       1.0115e-01, -6.9623e-02,  5.2182e-02,  1.3080e-01, -1.1977e-01,\n",
              "                      -3.7490e-02, -4.6126e-02,  9.0372e-03,  1.1526e-01, -2.0363e-01,\n",
              "                      -1.3989e-01, -7.3157e-02,  5.1071e-02, -9.3529e-03,  6.8500e-02,\n",
              "                      -1.1484e-01, -1.7626e-01, -1.6887e-01, -1.6771e-01, -3.3686e-01,\n",
              "                      -6.7594e-02, -8.9972e-02, -8.7449e-03, -1.0645e-01, -1.1829e-01,\n",
              "                       9.5698e-03, -2.9245e-02, -1.1140e-01, -1.8753e-01,  1.1292e-01,\n",
              "                      -9.6148e-04, -1.3718e-01, -3.6572e-01, -1.8909e-01, -3.9604e-02,\n",
              "                      -2.2451e-01, -1.6246e-01, -9.4963e-03, -5.2154e-02, -1.2648e-02,\n",
              "                       5.5003e-02, -1.9619e-01, -6.2146e-02, -5.4978e-02, -2.4895e-01,\n",
              "                      -1.0214e-02, -1.1266e-01, -1.9561e-01, -1.0977e-01, -2.6921e-01,\n",
              "                      -1.6384e-01, -3.6319e-02,  9.1942e-02,  9.1010e-02, -7.9323e-02,\n",
              "                      -1.4979e-01, -1.1801e-01, -9.2355e-02, -7.1771e-02, -3.1115e-02,\n",
              "                      -1.4218e-01,  8.6042e-03,  2.7537e-01,  4.4772e-02, -6.7111e-02,\n",
              "                       1.1802e-01,  1.0349e-03, -5.1197e-02, -9.2979e-02, -4.6844e-02,\n",
              "                       1.2176e-02,  3.2070e-02, -2.6537e-02, -5.5528e-03,  5.9944e-02,\n",
              "                      -8.8440e-02,  1.6107e-01, -1.2714e-01, -2.1059e-01, -1.2094e-01,\n",
              "                      -1.4439e-01,  5.0440e-02, -3.8039e-02, -1.0339e-01,  7.3168e-03,\n",
              "                      -2.2809e-04, -7.8230e-02, -1.1057e-01, -3.8069e-02, -8.1529e-02,\n",
              "                      -1.3898e-01,  3.4860e-02, -9.7042e-02,  4.0996e-02, -2.6077e-01,\n",
              "                       8.7501e-02, -5.3878e-02,  2.6466e-02,  1.0387e-01, -6.6683e-02,\n",
              "                       1.9195e-03, -7.0809e-02, -1.8075e-02, -2.2633e-01, -2.5321e-02,\n",
              "                      -1.2333e-01, -1.0764e-01, -1.9056e-02,  5.8949e-02,  4.7552e-02,\n",
              "                      -2.3407e-01,  1.3717e-01,  7.5756e-02, -1.6236e-01,  1.4435e-01,\n",
              "                      -3.4916e-02, -9.4186e-02, -1.1418e-01, -1.2135e-01,  4.8394e-02,\n",
              "                       5.1629e-02,  1.4589e-02, -5.6514e-02, -1.7998e-02, -2.4315e-01,\n",
              "                      -3.1303e-01, -1.1850e-01,  3.2354e-03, -6.5936e-02,  1.7397e-01,\n",
              "                       2.9035e-02, -1.9678e-01, -6.0952e-02,  1.8797e-01, -1.7761e-01,\n",
              "                      -1.5759e-01, -5.8067e-02, -3.2160e-01, -5.9737e-02,  8.0048e-03,\n",
              "                      -2.2228e-01, -3.3135e-01,  1.7218e-01, -4.1710e-02, -6.0949e-02,\n",
              "                      -3.1688e-02,  9.1932e-02,  3.4882e-02,  1.6528e-02, -1.5216e-01,\n",
              "                      -1.9015e-01, -2.0585e-01, -5.4439e-02, -1.6193e-01, -1.3014e-01,\n",
              "                       2.6479e-02,  5.3482e-02, -6.7155e-02,  8.1577e-02, -1.3330e-01,\n",
              "                      -1.1139e-01, -9.9466e-02, -1.7282e-02, -1.3859e-01,  1.0971e-02,\n",
              "                      -2.1068e-01, -6.1677e-02, -1.8726e-01,  5.3318e-02, -1.0359e-02,\n",
              "                       1.5775e-01, -9.0122e-04, -5.7336e-03, -1.2305e-01, -1.8983e-01,\n",
              "                       4.4789e-02,  1.1669e-03, -2.8817e-01,  2.2098e-01, -1.9168e-01,\n",
              "                       1.5674e-01, -1.9502e-01, -2.7147e-01,  1.5108e-01, -4.0944e-01,\n",
              "                       6.8431e-02, -1.2970e-01, -8.0167e-02, -1.0147e-01, -2.8143e-01,\n",
              "                      -6.0974e-02, -1.1941e-01, -1.3738e-01, -3.0218e-01, -5.4395e-02,\n",
              "                       5.5166e-02])),\n",
              "             ('batch_norm2.running_var',\n",
              "              tensor([0.1949, 0.1060, 0.1334, 0.1641, 0.0627, 0.1670, 0.1955, 0.1239, 0.1651,\n",
              "                      0.1836, 0.1034, 0.2048, 0.1910, 0.1908, 0.1620, 0.1421, 0.1995, 0.1773,\n",
              "                      0.1634, 0.3068, 0.1612, 0.1684, 0.1390, 0.1914, 0.1495, 0.3800, 0.1480,\n",
              "                      0.2473, 0.1905, 0.1722, 0.1639, 0.2101, 0.2834, 0.2181, 0.1850, 0.1390,\n",
              "                      0.1737, 0.2484, 0.2063, 0.1711, 0.1381, 0.2337, 0.1439, 0.1695, 0.1589,\n",
              "                      0.3778, 0.2354, 0.1441, 0.1437, 0.1476, 0.3012, 0.3064, 0.2653, 0.1899,\n",
              "                      0.0974, 0.1720, 0.2919, 0.1809, 0.3963, 0.1224, 0.2253, 0.1189, 0.2525,\n",
              "                      0.2064, 0.1629, 0.1641, 0.1967, 0.2014, 0.1725, 0.2566, 0.1857, 0.1288,\n",
              "                      0.2863, 0.1775, 0.1284, 0.2510, 0.1531, 0.1552, 0.1616, 0.2133, 0.1321,\n",
              "                      0.1510, 0.1896, 0.1531, 0.1990, 0.2277, 0.1750, 0.1329, 0.2368, 0.2488,\n",
              "                      0.1286, 0.1232, 0.2737, 0.1564, 0.1091, 0.1268, 0.1879, 0.1450, 0.1982,\n",
              "                      0.1907, 0.1329, 0.1752, 0.1037, 0.2815, 0.0857, 0.2801, 0.1360, 0.1394,\n",
              "                      0.1188, 0.3304, 0.2176, 0.0932, 0.0890, 0.1170, 0.2320, 0.2159, 0.1956,\n",
              "                      0.2086, 0.2549, 0.1707, 0.1153, 0.1243, 0.1624, 0.1830, 0.1673, 0.2420,\n",
              "                      0.2362, 0.2189, 0.1233, 0.3471, 0.1160, 0.2222, 0.1347, 0.1547, 0.2061,\n",
              "                      0.2551, 0.2209, 0.1762, 0.1098, 0.1545, 0.3052, 0.1840, 0.2038, 0.1527,\n",
              "                      0.2232, 0.1827, 0.2081, 0.1723, 0.1819, 0.1034, 0.1694, 0.1597, 0.1445,\n",
              "                      0.1987, 0.1387, 0.2782, 0.1938, 0.2399, 0.1745, 0.2140, 0.1643, 0.1801,\n",
              "                      0.1899, 0.1087, 0.1608, 0.1409, 0.1538, 0.2523, 0.2638, 0.1481, 0.2656,\n",
              "                      0.2059, 0.2393, 0.1138, 0.2499, 0.1664, 0.1859, 0.2275, 0.0943, 0.1897,\n",
              "                      0.3009, 0.1558, 0.1406, 0.1508, 0.2333, 0.2681, 0.0977, 0.1450, 0.1191,\n",
              "                      0.1863, 0.2265, 0.1634, 0.0744, 0.2339, 0.2645, 0.1526, 0.1950, 0.3012,\n",
              "                      0.1535, 0.2338, 0.1571, 0.2595, 0.2331, 0.1641, 0.1040, 0.2028, 0.2215,\n",
              "                      0.1946, 0.1244, 0.1420, 0.1933, 0.2001, 0.0804, 0.1741, 0.2206, 0.1282,\n",
              "                      0.2937, 0.1733, 0.1769, 0.1496, 0.1491, 0.1670, 0.1634, 0.2220, 0.2001,\n",
              "                      0.1380, 0.1796, 0.1251, 0.2395, 0.1845, 0.1420, 0.0772, 0.1436, 0.1488,\n",
              "                      0.2996, 0.1581, 0.1582, 0.1643, 0.2286, 0.2964, 0.2203, 0.2185, 0.1232,\n",
              "                      0.2353, 0.3508, 0.1625, 0.2050, 0.1572, 0.2820, 0.1880, 0.1718, 0.1954,\n",
              "                      0.1932, 0.2867, 0.1717, 0.1448])),\n",
              "             ('batch_norm2.num_batches_tracked', tensor(7296)),\n",
              "             ('dense3.weight',\n",
              "              tensor([[-0.0946, -0.0165, -0.1416,  ...,  0.0446, -0.0006,  0.0515],\n",
              "                      [ 0.0477, -0.0510, -0.0083,  ...,  0.0642,  0.0406, -0.0121],\n",
              "                      [-0.0678,  0.0455, -0.0448,  ..., -0.0060, -0.0315, -0.0181],\n",
              "                      ...,\n",
              "                      [-0.0076,  0.0056,  0.0289,  ...,  0.0009,  0.0416,  0.0056],\n",
              "                      [ 0.0681, -0.0311, -0.0264,  ..., -0.0577,  0.0633,  0.0625],\n",
              "                      [-0.0544, -0.0013,  0.0135,  ..., -0.1516,  0.0238,  0.0582]])),\n",
              "             ('dense3.bias',\n",
              "              tensor([ 4.3348e-05, -7.5475e-05, -3.9495e-05, -3.6243e-05, -2.3450e-12,\n",
              "                       3.4354e-05, -5.2507e-05, -2.8115e-04, -2.9574e-06, -8.3854e-06,\n",
              "                       3.9269e-05,  8.2432e-05, -2.0828e-06, -1.7749e-05, -4.7685e-06,\n",
              "                       4.5724e-05, -3.5523e-05,  3.1636e-06,  5.9740e-06,  1.9130e-05,\n",
              "                       4.1283e-06, -7.0854e-11,  4.5884e-05,  2.3805e-05, -1.0217e-05,\n",
              "                       4.1792e-06,  2.1215e-05,  1.7657e-05,  8.0268e-06,  1.4658e-04,\n",
              "                       1.5040e-04, -1.3493e-05, -1.1196e-05, -1.5549e-06,  3.5281e-05,\n",
              "                       9.3791e-06,  6.1263e-10, -1.9152e-07, -3.1974e-05, -4.1842e-05,\n",
              "                      -2.6583e-05, -1.1394e-05, -4.6713e-06, -4.2708e-05, -8.6006e-05,\n",
              "                       2.8276e-05,  3.1229e-05, -5.3025e-05,  1.5060e-05, -9.7553e-05,\n",
              "                       1.0947e-05,  3.3658e-05,  4.0719e-06,  4.0911e-05, -7.0035e-05,\n",
              "                      -1.1705e-04,  9.6961e-06, -1.1141e-04,  3.6251e-06,  2.7652e-10,\n",
              "                      -1.2370e-06,  2.8898e-09,  7.3794e-05, -4.3816e-05, -2.5847e-05,\n",
              "                       1.6319e-04, -7.4299e-06, -5.5459e-07, -3.2037e-05, -1.6540e-05,\n",
              "                      -9.2077e-05,  9.8379e-06, -5.0114e-05,  4.4746e-05,  1.3709e-05,\n",
              "                       1.9112e-05,  1.0674e-05, -2.1104e-05,  4.8304e-06, -1.4312e-10,\n",
              "                      -1.1227e-05,  4.1353e-05,  4.9744e-06, -1.7043e-05,  1.4701e-06,\n",
              "                      -9.7385e-05,  1.1231e-04,  1.6457e-05, -1.6931e-05, -1.9834e-05,\n",
              "                       2.5727e-06,  9.7048e-06, -1.8289e-05,  1.8826e-05,  6.3972e-06,\n",
              "                       1.0436e-05, -9.3382e-05,  7.7171e-05, -1.1145e-06,  1.2152e-05,\n",
              "                      -2.8212e-05,  4.2973e-05,  2.3221e-06, -1.0756e-05,  5.7662e-05,\n",
              "                       7.6264e-05, -3.9340e-05, -2.4489e-05, -3.9085e-09,  1.8613e-05,\n",
              "                       3.6063e-05,  5.5719e-05,  2.8516e-05, -2.1040e-05, -2.0624e-05,\n",
              "                       3.0363e-05, -4.4326e-05, -4.4758e-05, -1.0136e-05, -4.7613e-05,\n",
              "                       7.6699e-06, -1.1220e-06, -1.2188e-05,  1.9207e-05, -1.5266e-04,\n",
              "                       6.5247e-06,  6.3835e-05,  3.1271e-05, -4.0214e-05, -1.1732e-06,\n",
              "                       3.0159e-05,  6.4149e-05,  2.1072e-05, -2.5831e-05, -3.9313e-05,\n",
              "                       5.9641e-06, -5.0394e-05,  8.4438e-05,  1.2123e-04,  2.6999e-05,\n",
              "                      -1.0797e-08,  4.8825e-05,  4.5788e-05,  6.6390e-05,  7.5055e-06,\n",
              "                      -1.5281e-06, -3.3743e-05, -4.5486e-05, -1.2582e-04,  2.6679e-05,\n",
              "                      -4.4657e-05, -1.5472e-05, -1.3609e-05,  8.3462e-05, -3.6570e-05,\n",
              "                      -1.6496e-04,  6.3374e-05,  6.8299e-05, -4.4534e-05,  5.8822e-05,\n",
              "                      -6.2459e-05,  3.4625e-09,  2.0011e-05,  2.6645e-06, -3.4506e-05,\n",
              "                      -5.8259e-05,  5.9587e-06,  9.3883e-07,  2.8735e-05, -3.4140e-05,\n",
              "                       4.7004e-05,  2.3870e-05,  1.3826e-06, -2.9410e-05, -2.5472e-06,\n",
              "                       1.0636e-05, -2.2364e-05,  4.2466e-06, -2.5712e-05,  1.0323e-05,\n",
              "                      -7.7739e-05, -4.1019e-05,  1.1946e-04,  1.0290e-04,  2.3941e-05,\n",
              "                      -5.2465e-05, -2.7163e-05, -1.6387e-05, -3.4222e-05, -9.5223e-05,\n",
              "                      -2.3940e-06,  1.2240e-05,  1.9553e-05,  2.5371e-05, -1.1955e-04,\n",
              "                      -1.1397e-04, -2.0302e-12,  9.3966e-06,  9.3039e-06, -1.6468e-05,\n",
              "                      -9.2517e-05, -1.6174e-05, -8.2299e-06, -4.9619e-05,  1.9831e-05,\n",
              "                       4.1251e-05, -2.4777e-05,  3.4804e-05, -9.7154e-06, -2.1971e-05,\n",
              "                       6.9483e-06, -3.1331e-07,  1.0756e-05, -2.3553e-05, -2.1821e-05,\n",
              "                      -2.0449e-05,  2.5451e-05,  2.9236e-05,  2.2011e-05, -9.7208e-05,\n",
              "                      -6.2019e-05, -2.1138e-05, -1.6469e-05, -5.5417e-05, -4.9663e-05,\n",
              "                       3.8322e-05, -4.8541e-05, -1.6074e-07,  1.3223e-05,  1.9844e-05,\n",
              "                      -2.0124e-05, -1.4875e-05,  7.0390e-06, -4.1927e-06,  1.8298e-09,\n",
              "                      -9.2853e-06,  5.1240e-05,  2.4595e-05,  4.3452e-06,  4.1050e-05,\n",
              "                       2.1519e-05,  2.0014e-06,  7.6573e-05, -2.1416e-05,  4.5412e-06,\n",
              "                      -1.6197e-05,  1.5343e-06,  1.3451e-06, -2.8906e-05,  8.4793e-10,\n",
              "                       5.8997e-05,  2.5245e-05, -1.1710e-05,  2.6197e-05, -1.0480e-06,\n",
              "                      -6.5496e-05])),\n",
              "             ('batch_norm3.weight',\n",
              "              tensor([ 1.8658e-01,  2.3499e-01,  2.5611e-01,  1.2508e-01, -2.9863e-06,\n",
              "                       2.8834e-01,  2.1846e-01,  2.2911e-01,  2.0136e-01,  2.9119e-01,\n",
              "                       3.2323e-01,  2.2274e-01,  2.3542e-01,  2.2813e-01,  2.0053e-01,\n",
              "                       2.2647e-01,  2.1029e-01,  2.1465e-01,  2.1184e-01,  3.5634e-01,\n",
              "                       2.4309e-01,  9.0206e-05,  2.5813e-01,  1.8101e-01,  3.0531e-01,\n",
              "                       1.8575e-01,  2.5229e-01,  1.1619e-01,  2.2540e-01,  3.0780e-01,\n",
              "                       2.2354e-01,  2.5982e-01,  1.8552e-01,  3.1097e-01,  2.4805e-01,\n",
              "                       2.5232e-01,  2.9444e-04,  2.0536e-01,  2.6360e-01,  1.3321e-01,\n",
              "                       2.9844e-01,  2.4205e-01,  1.5399e-01,  1.5046e-01,  1.9140e-01,\n",
              "                       1.9039e-01,  1.1654e-01,  3.0788e-01,  1.7376e-01,  3.2214e-01,\n",
              "                       2.2893e-01,  2.3388e-01,  2.5504e-01,  3.6301e-01,  2.7121e-01,\n",
              "                       3.3929e-01,  1.0028e-01,  1.6130e-01,  1.2577e-01,  5.2473e-04,\n",
              "                       2.5579e-01, -9.8085e-04,  3.2292e-01,  3.9371e-01,  2.9569e-01,\n",
              "                       3.5731e-01,  1.7992e-01,  2.2531e-01,  2.7538e-01,  2.8417e-01,\n",
              "                       2.9395e-01,  2.4086e-01,  2.1939e-01,  2.8312e-01,  2.6505e-01,\n",
              "                       2.5695e-01,  2.3046e-01,  1.6385e-01,  1.9374e-01, -7.0759e-05,\n",
              "                       2.7199e-01,  1.4792e-01,  1.8931e-01,  3.0299e-01,  1.6611e-01,\n",
              "                       2.4641e-01,  2.1913e-01,  1.5501e-01,  2.7933e-01,  2.5135e-01,\n",
              "                       2.3168e-01,  3.3917e-01,  2.7499e-01,  1.4511e-01,  2.4318e-01,\n",
              "                       2.4117e-01,  3.5646e-01,  3.1202e-01,  6.6089e-02,  2.6681e-01,\n",
              "                       3.4108e-01,  2.7379e-01,  1.8945e-01,  1.2238e-01,  1.7998e-01,\n",
              "                       3.6926e-01,  3.6001e-01,  2.4633e-01, -2.0373e-03,  2.1946e-01,\n",
              "                       2.7491e-01,  3.5197e-01,  2.6043e-01,  1.4456e-01,  2.1982e-01,\n",
              "                       1.1080e-01,  3.5524e-01,  3.1980e-01,  1.5891e-01,  2.3719e-01,\n",
              "                       1.7775e-01,  2.7825e-01,  2.4379e-01,  2.3675e-01,  2.4367e-01,\n",
              "                       2.7171e-01,  3.5841e-01,  3.5942e-01,  2.0148e-01,  2.2031e-01,\n",
              "                       3.1676e-01,  2.3873e-01,  3.0708e-01,  3.3365e-01,  3.1770e-01,\n",
              "                       2.4327e-02,  2.6556e-01,  3.0692e-01,  2.4516e-01,  2.7801e-01,\n",
              "                       6.2975e-03,  2.9301e-01,  2.9791e-01,  2.2057e-01,  3.0626e-01,\n",
              "                       3.0699e-01,  1.8216e-01,  2.1484e-01,  2.5424e-01,  2.9996e-01,\n",
              "                       2.3435e-01,  2.5920e-01,  2.3673e-01,  2.6734e-01,  1.6164e-01,\n",
              "                       1.6287e-01,  2.8268e-01,  2.4606e-01,  2.9229e-01,  2.9970e-01,\n",
              "                       3.2722e-01,  1.1494e-03,  2.3677e-01,  7.1559e-02,  2.5412e-01,\n",
              "                       1.8710e-01,  3.2937e-01,  2.4119e-02,  1.7108e-01,  1.9365e-01,\n",
              "                       2.5448e-01,  3.1316e-01,  2.2025e-01,  3.5234e-01,  1.5313e-01,\n",
              "                       2.2760e-01,  2.9314e-01,  2.9827e-01,  2.7993e-01,  1.9417e-01,\n",
              "                       1.3791e-01,  3.1891e-01,  2.4610e-01,  1.9380e-01,  1.2138e-01,\n",
              "                       2.7956e-01,  3.0421e-01,  2.2860e-01,  3.1039e-01,  1.9744e-01,\n",
              "                       1.8773e-01,  2.4236e-01,  2.3685e-01,  2.7406e-01,  3.1382e-01,\n",
              "                       2.6787e-01, -5.7568e-06,  1.7227e-01,  1.6113e-01,  3.1609e-01,\n",
              "                       3.6948e-01,  2.0902e-01,  9.1201e-02,  3.3651e-01,  2.7324e-01,\n",
              "                       2.7880e-01,  2.1108e-01,  2.1864e-01,  2.5643e-01,  2.4467e-01,\n",
              "                       9.6380e-02,  1.9057e-01,  2.1479e-01,  2.0678e-01,  1.5508e-01,\n",
              "                       2.4692e-01,  3.1212e-01,  1.8902e-01,  3.6664e-01,  3.1577e-01,\n",
              "                       3.0136e-01,  1.8881e-01,  1.7471e-01,  4.0461e-01,  2.8760e-01,\n",
              "                       3.7996e-01,  2.4421e-01,  2.0955e-01,  2.8878e-01,  2.1973e-01,\n",
              "                       4.3059e-01,  2.9730e-01,  2.7545e-01,  1.1787e-01,  7.8096e-04,\n",
              "                       2.7266e-01,  2.8361e-01,  2.1568e-01,  3.9047e-01,  1.4991e-01,\n",
              "                       1.4000e-01,  2.3278e-01,  2.2842e-01,  2.0205e-01,  1.5337e-01,\n",
              "                       2.0486e-01,  2.9838e-01,  1.6356e-01,  2.2265e-01, -3.3651e-04,\n",
              "                       2.7863e-01,  1.9599e-01,  1.6758e-01,  2.0034e-01,  2.0980e-01,\n",
              "                       3.1192e-01])),\n",
              "             ('batch_norm3.bias',\n",
              "              tensor([-2.3877e-01, -2.4296e-01, -2.5186e-01, -1.0136e-01, -1.3548e-03,\n",
              "                      -2.0364e-01, -2.1891e-01, -1.8625e-01, -1.7769e-01, -2.1450e-01,\n",
              "                      -1.5042e-01, -3.6783e-01, -1.7036e-01, -2.1062e-01, -3.0275e-01,\n",
              "                      -1.7741e-01, -1.9044e-01, -2.0378e-01, -1.2919e-01, -2.7797e-01,\n",
              "                      -1.8304e-01, -7.3500e-03, -1.5398e-01, -3.1537e-02, -2.0520e-01,\n",
              "                      -1.4765e-01, -1.7311e-01, -2.5665e-02, -1.8348e-01, -2.4844e-01,\n",
              "                      -2.7100e-01, -3.1302e-01, -2.8891e-01, -2.7028e-01, -2.4313e-01,\n",
              "                      -2.9113e-01, -4.8314e-03, -2.5716e-01, -1.7345e-01, -3.2773e-01,\n",
              "                      -2.3047e-01, -2.5027e-01, -1.1025e-01, -1.5831e-01, -3.8913e-01,\n",
              "                      -1.3855e-01, -1.0599e-01, -3.0441e-01, -1.1845e-01, -2.4890e-01,\n",
              "                      -1.5985e-01, -1.8376e-01, -1.8986e-01, -3.3431e-01, -1.9649e-01,\n",
              "                      -2.4678e-01, -6.8520e-02, -1.2590e-01, -1.0321e-01, -3.4263e-03,\n",
              "                      -1.6549e-01, -3.0577e-03, -2.0525e-01, -3.4797e-01, -2.3301e-01,\n",
              "                      -2.6043e-01, -1.7322e-01, -2.6609e-01, -2.6431e-01, -2.1120e-01,\n",
              "                      -2.3846e-01, -1.8505e-01, -3.1996e-01, -2.2860e-01, -1.0185e-01,\n",
              "                      -1.2602e-01, -2.2328e-01, -1.1460e-01, -1.5276e-01, -6.2524e-03,\n",
              "                      -2.2285e-01, -1.8206e-01, -1.6434e-01, -2.5896e-01, -2.6531e-01,\n",
              "                      -3.2328e-01, -2.2794e-01, -1.0271e-01, -2.7552e-01, -1.9894e-01,\n",
              "                      -1.7150e-01, -3.3359e-01, -3.8605e-01, -6.3502e-02, -3.4311e-01,\n",
              "                      -2.8253e-01, -2.5899e-01, -2.4480e-01, -5.8537e-02, -8.8029e-02,\n",
              "                      -3.1323e-01, -2.6085e-01, -7.2635e-02, -1.1645e-01, -9.9556e-02,\n",
              "                      -3.0346e-01, -1.9260e-01, -2.5901e-01, -4.8668e-02, -2.5172e-01,\n",
              "                      -2.1606e-01, -3.5392e-01, -3.2402e-01, -3.3698e-01, -1.5750e-01,\n",
              "                      -7.3807e-02, -2.7623e-01, -2.4585e-01, -2.7453e-01, -1.9081e-01,\n",
              "                      -1.2564e-01, -2.3950e-01, -1.4326e-01, -1.1572e-01, -3.5101e-01,\n",
              "                      -3.3659e-01, -2.7449e-01, -3.3721e-01, -2.0451e-01, -1.6358e-01,\n",
              "                      -2.0947e-01, -1.9911e-01, -2.0329e-01, -2.4206e-01, -2.2274e-01,\n",
              "                      -1.0470e-01, -1.0936e-01, -2.7044e-01, -2.5386e-01, -1.0104e-01,\n",
              "                      -2.5029e-02, -2.2629e-01, -2.4659e-01, -1.6607e-01, -2.7433e-01,\n",
              "                      -4.3105e-01, -1.7361e-01, -1.8247e-01, -2.0669e-01, -1.9326e-01,\n",
              "                      -1.8352e-01, -2.0438e-01, -2.2353e-01, -2.2550e-01, -7.7554e-02,\n",
              "                      -3.2236e-01, -3.0837e-01, -3.8866e-01, -2.4869e-01, -2.2502e-01,\n",
              "                      -3.3593e-01, -1.8773e-02, -1.4344e-01, -4.3375e-02, -1.8935e-01,\n",
              "                      -1.1631e-01, -2.3867e-01, -3.6105e-02, -1.1604e-01, -1.6851e-01,\n",
              "                      -2.2199e-01, -2.3870e-01, -2.2883e-01, -2.3744e-01, -1.8282e-01,\n",
              "                      -2.7378e-01, -2.8361e-01, -3.6272e-01, -1.9567e-01, -2.6083e-01,\n",
              "                      -9.9306e-02, -2.8219e-01, -2.1834e-01, -1.6227e-01, -9.4630e-02,\n",
              "                      -1.8897e-01, -3.2812e-01, -1.3672e-01, -1.9302e-01, -2.3639e-01,\n",
              "                      -7.1468e-02, -2.0985e-01, -2.3141e-01, -2.1993e-01, -2.6466e-01,\n",
              "                      -2.1880e-01, -1.9726e-04, -2.0822e-01, -2.1413e-01, -2.2885e-01,\n",
              "                      -3.3111e-01, -3.1738e-01, -7.2711e-02, -2.8421e-01, -2.4263e-01,\n",
              "                      -2.2975e-01, -7.9466e-02, -2.7352e-01, -1.8655e-01, -1.1280e-01,\n",
              "                      -8.8275e-02, -2.2177e-01, -2.3922e-01, -1.4261e-01, -1.0804e-01,\n",
              "                      -1.4299e-01, -2.6397e-01, -5.3508e-02, -3.4533e-01, -1.6398e-01,\n",
              "                      -2.4066e-01, -1.6350e-01, -2.7984e-01, -3.0674e-01, -2.3465e-01,\n",
              "                      -2.0217e-01, -1.4365e-01, -1.3264e-01, -1.5308e-01, -2.6894e-01,\n",
              "                      -2.7697e-01, -3.0413e-01, -1.7355e-01, -8.1062e-02, -4.6936e-02,\n",
              "                      -2.2522e-01, -2.4595e-01, -3.3450e-01, -3.0277e-01, -1.2801e-01,\n",
              "                      -7.1405e-02, -1.8599e-01, -1.9091e-01, -3.1794e-01, -1.5580e-01,\n",
              "                      -1.1316e-01, -2.7731e-01, -1.1339e-01, -1.1241e-01, -2.2122e-02,\n",
              "                      -3.3915e-01, -1.1716e-01, -2.6663e-01, -1.9945e-01, -1.6168e-01,\n",
              "                      -3.2094e-01])),\n",
              "             ('batch_norm3.running_mean',\n",
              "              tensor([ 2.7594e-02, -6.2805e-02, -1.3246e-01, -7.9759e-02,  8.2428e-09,\n",
              "                      -1.0059e-01, -1.2520e-01, -8.1085e-02, -3.8019e-02, -5.5446e-02,\n",
              "                      -7.1912e-02, -4.3196e-02, -5.0290e-02, -4.2470e-02,  1.6456e-02,\n",
              "                      -9.1919e-02, -9.8906e-02, -7.8711e-02,  1.8376e-02, -7.3163e-02,\n",
              "                      -6.5810e-02, -4.2465e-06, -5.4591e-02, -5.7337e-02, -8.0436e-02,\n",
              "                      -1.0535e-01, -1.1360e-01, -3.3627e-02, -6.2699e-02, -1.4639e-01,\n",
              "                      -9.5951e-02, -4.0459e-02, -2.9438e-02, -6.7626e-02, -1.1351e-01,\n",
              "                      -5.1173e-02,  1.4211e-05, -1.1885e-02, -4.6443e-02,  4.8520e-02,\n",
              "                      -1.0261e-01, -1.9521e-02, -1.0752e-01, -7.0871e-02,  1.0055e-01,\n",
              "                      -8.7851e-02, -1.8565e-02, -1.0287e-01, -8.5069e-02, -1.0171e-01,\n",
              "                      -6.2017e-02, -1.1689e-01, -2.8194e-02, -8.4579e-02, -9.2839e-02,\n",
              "                      -1.2011e-01, -4.7000e-02, -1.0688e-01, -1.0069e-01, -1.2041e-05,\n",
              "                      -1.0147e-01,  8.4483e-06, -8.1492e-02, -1.3741e-01, -6.5739e-02,\n",
              "                      -1.4368e-01, -1.0350e-02, -5.7995e-02, -7.6405e-02, -6.2273e-02,\n",
              "                      -1.2200e-01, -1.7370e-02, -4.1533e-02, -1.3929e-01, -7.5911e-02,\n",
              "                      -7.8531e-02, -6.4184e-02, -8.1495e-02, -7.5568e-02,  1.8422e-06,\n",
              "                      -8.0995e-02, -3.4515e-02, -4.7469e-02, -1.0874e-01, -1.8006e-02,\n",
              "                      -5.0497e-02, -8.9609e-02, -5.3397e-02, -1.0934e-01, -7.6860e-02,\n",
              "                      -8.3062e-02, -7.6602e-02, -4.6157e-02, -6.6015e-02, -5.0557e-02,\n",
              "                      -7.2854e-02, -1.0221e-01, -1.0553e-01, -7.2086e-02, -5.5804e-02,\n",
              "                      -1.2041e-01, -1.1946e-01, -3.9814e-02, -3.5776e-02, -4.5366e-02,\n",
              "                      -1.1369e-01, -9.8259e-02, -8.4481e-02,  2.9335e-03, -6.0159e-02,\n",
              "                      -9.7631e-02, -7.0730e-02, -9.3921e-02,  9.0805e-02, -1.0958e-01,\n",
              "                      -5.7326e-02, -1.1984e-01, -1.1610e-01,  1.3773e-02, -4.8919e-02,\n",
              "                      -5.8622e-02, -4.6854e-02, -3.5623e-02, -5.8421e-02, -8.1273e-02,\n",
              "                      -3.6178e-03, -9.1799e-02, -1.2430e-01, -4.1384e-02, -5.3493e-02,\n",
              "                      -7.4213e-02, -1.2619e-01, -7.3912e-02, -7.1090e-02, -1.0802e-01,\n",
              "                       2.9563e-02, -7.8509e-02, -9.7046e-02, -9.6611e-02, -6.2845e-02,\n",
              "                      -2.6917e-04, -7.1481e-02, -7.0596e-02, -1.1049e-01, -1.2108e-01,\n",
              "                      -4.9142e-02, -9.7074e-02, -8.8192e-02, -7.3967e-02, -1.3952e-01,\n",
              "                      -9.6087e-02, -1.0907e-01, -5.6709e-02, -1.3449e-01, -6.0138e-02,\n",
              "                       8.2689e-02, -7.2306e-02, -2.7102e-02, -7.9045e-02, -6.4911e-02,\n",
              "                      -8.7008e-02,  3.2989e-05, -6.9235e-02, -1.5274e-02, -1.0079e-01,\n",
              "                      -8.8949e-02, -1.0543e-01, -6.6055e-03, -8.3115e-02, -8.0741e-02,\n",
              "                      -8.2906e-02, -1.2727e-01, -4.7566e-02, -9.5126e-02, -5.7348e-03,\n",
              "                      -2.3925e-02, -4.8179e-02, -1.4823e-02, -1.2514e-01, -2.2788e-02,\n",
              "                      -1.1635e-01, -8.1927e-02, -6.8319e-02, -1.1590e-01, -5.2435e-02,\n",
              "                      -9.0571e-02, -5.0116e-02, -7.3640e-02, -1.1931e-01, -7.3470e-02,\n",
              "                      -3.3787e-02, -9.8475e-02, -5.2897e-02, -7.6611e-02, -8.8823e-02,\n",
              "                      -1.1123e-01, -2.2870e-09, -1.2570e-02, -1.5875e-02, -9.5138e-02,\n",
              "                      -9.5767e-02,  4.2162e-02, -4.0148e-02, -1.1450e-01, -9.5631e-02,\n",
              "                      -8.9253e-02, -5.0366e-02, -7.5735e-02, -6.3859e-02, -5.4832e-02,\n",
              "                      -1.9860e-02, -8.0414e-03, -3.7126e-02, -3.7887e-02, -1.0470e-01,\n",
              "                      -1.0837e-01, -1.0675e-01, -7.7011e-02, -1.4928e-01, -8.0297e-02,\n",
              "                      -9.7712e-02, -6.5896e-02, -3.3711e-02, -8.6745e-02, -1.4404e-01,\n",
              "                      -7.8859e-02, -1.0267e-01, -7.1564e-02, -8.4375e-02,  1.0238e-02,\n",
              "                      -9.2635e-02, -9.1974e-02, -9.0662e-02, -3.8192e-02,  1.2358e-03,\n",
              "                      -4.8915e-02, -1.0210e-01,  3.5956e-02, -7.5678e-02, -7.7528e-02,\n",
              "                      -1.4076e-02, -6.3095e-02, -9.6364e-02, -2.5546e-02, -5.7409e-02,\n",
              "                      -2.2064e-02, -1.2643e-01, -4.2619e-02, -6.5594e-02,  4.1757e-05,\n",
              "                      -6.9145e-02, -5.6578e-02, -1.8869e-02, -5.9193e-02, -5.4789e-03,\n",
              "                      -1.4420e-01])),\n",
              "             ('batch_norm3.running_var',\n",
              "              tensor([8.1724e-03, 8.9586e-03, 1.3767e-02, 9.3206e-03, 2.6719e-14, 1.7385e-02,\n",
              "                      1.5469e-02, 1.1905e-02, 1.0242e-02, 1.3651e-02, 2.4954e-02, 1.2491e-02,\n",
              "                      1.2485e-02, 1.4535e-02, 1.0988e-02, 1.2305e-02, 1.5246e-02, 1.5319e-02,\n",
              "                      1.6188e-02, 2.1186e-02, 1.2046e-02, 8.0560e-10, 1.1571e-02, 1.2197e-02,\n",
              "                      1.8076e-02, 1.2933e-02, 1.5930e-02, 1.0194e-02, 1.4331e-02, 2.4615e-02,\n",
              "                      1.3617e-02, 1.4488e-02, 7.9352e-03, 1.4808e-02, 1.6559e-02, 1.5351e-02,\n",
              "                      1.2306e-08, 1.2327e-02, 1.5826e-02, 1.0752e-02, 1.7206e-02, 8.6639e-03,\n",
              "                      1.3358e-02, 1.0787e-02, 1.4642e-02, 1.0970e-02, 5.9696e-03, 1.7736e-02,\n",
              "                      1.1727e-02, 1.6928e-02, 1.4424e-02, 1.5627e-02, 1.5859e-02, 1.9525e-02,\n",
              "                      1.6043e-02, 1.9594e-02, 4.3318e-03, 1.2869e-02, 9.1507e-03, 1.2340e-09,\n",
              "                      2.0621e-02, 8.1913e-09, 1.9566e-02, 2.2740e-02, 1.7637e-02, 2.2681e-02,\n",
              "                      9.6627e-03, 1.1393e-02, 1.1144e-02, 1.5991e-02, 1.6103e-02, 1.1089e-02,\n",
              "                      1.3530e-02, 2.0870e-02, 1.8633e-02, 1.8738e-02, 8.6965e-03, 8.2024e-03,\n",
              "                      1.1217e-02, 2.1401e-11, 1.6624e-02, 7.4979e-03, 1.3812e-02, 1.7335e-02,\n",
              "                      1.0460e-02, 1.3977e-02, 1.5178e-02, 7.8890e-03, 2.3819e-02, 1.6067e-02,\n",
              "                      1.5231e-02, 1.8594e-02, 1.3817e-02, 1.1474e-02, 1.7762e-02, 9.7089e-03,\n",
              "                      2.1989e-02, 2.1477e-02, 5.7267e-03, 1.9609e-02, 1.9087e-02, 2.0826e-02,\n",
              "                      1.1295e-02, 5.1736e-03, 6.9318e-03, 2.0812e-02, 2.4180e-02, 1.2314e-02,\n",
              "                      1.7960e-05, 1.3186e-02, 1.7109e-02, 1.7745e-02, 1.7274e-02, 1.4151e-02,\n",
              "                      1.5471e-02, 5.9340e-03, 2.1803e-02, 1.7048e-02, 9.1240e-03, 1.3246e-02,\n",
              "                      1.0614e-02, 2.0441e-02, 1.6275e-02, 1.4791e-02, 1.3044e-02, 1.3004e-02,\n",
              "                      2.0068e-02, 1.8344e-02, 1.2430e-02, 1.3283e-02, 2.3414e-02, 1.6097e-02,\n",
              "                      2.2529e-02, 2.1226e-02, 1.8295e-02, 2.1891e-03, 1.5733e-02, 1.6461e-02,\n",
              "                      1.2450e-02, 1.3537e-02, 3.8902e-07, 1.6318e-02, 1.7669e-02, 1.0877e-02,\n",
              "                      1.4178e-02, 1.5259e-02, 1.1376e-02, 1.1793e-02, 1.0115e-02, 2.3187e-02,\n",
              "                      1.6219e-02, 1.1401e-02, 1.6063e-02, 1.3860e-02, 9.3814e-03, 1.5338e-02,\n",
              "                      1.3320e-02, 1.0287e-02, 1.6919e-02, 1.6145e-02, 1.6931e-02, 9.0266e-09,\n",
              "                      1.6916e-02, 3.0817e-03, 1.6430e-02, 1.0785e-02, 2.4621e-02, 8.7802e-05,\n",
              "                      1.2462e-02, 1.3331e-02, 1.2387e-02, 2.0047e-02, 1.3664e-02, 2.0987e-02,\n",
              "                      8.1946e-03, 1.2971e-02, 2.2452e-02, 1.3920e-02, 1.5562e-02, 9.5789e-03,\n",
              "                      1.1118e-02, 1.9640e-02, 9.2940e-03, 1.4783e-02, 6.0789e-03, 1.3637e-02,\n",
              "                      1.6242e-02, 1.6823e-02, 2.0874e-02, 1.2721e-02, 1.5498e-02, 1.3454e-02,\n",
              "                      1.3663e-02, 1.8052e-02, 2.0260e-02, 1.6712e-02, 1.3012e-13, 8.3792e-03,\n",
              "                      8.0960e-03, 1.6971e-02, 2.0028e-02, 8.6933e-03, 2.6525e-03, 1.8570e-02,\n",
              "                      1.6734e-02, 1.7132e-02, 1.2764e-02, 1.2821e-02, 1.6980e-02, 1.6124e-02,\n",
              "                      4.9708e-03, 8.2513e-03, 9.9143e-03, 1.1303e-02, 1.0710e-02, 2.2393e-02,\n",
              "                      1.8171e-02, 1.4374e-02, 2.3080e-02, 1.6509e-02, 2.6610e-02, 1.5274e-02,\n",
              "                      1.1658e-02, 2.2289e-02, 1.8153e-02, 2.3266e-02, 1.5722e-02, 1.4761e-02,\n",
              "                      1.7224e-02, 8.0109e-03, 2.5816e-02, 1.6042e-02, 1.9519e-02, 7.4199e-03,\n",
              "                      2.9443e-06, 1.5728e-02, 1.7936e-02, 1.5602e-02, 2.4088e-02, 7.4616e-03,\n",
              "                      7.9690e-03, 1.3371e-02, 1.3832e-02, 9.2662e-03, 5.9781e-03, 1.1950e-02,\n",
              "                      1.8058e-02, 1.4901e-02, 1.1088e-02, 1.2584e-08, 1.4690e-02, 1.1655e-02,\n",
              "                      7.8309e-03, 1.0489e-02, 9.7425e-03, 1.9354e-02])),\n",
              "             ('batch_norm3.num_batches_tracked', tensor(7296)),\n",
              "             ('dense4.weight',\n",
              "              tensor([[-1.6695e-02, -3.7264e-03,  2.1053e-02,  ...,  1.0076e-02,\n",
              "                       -1.1290e-02,  9.2922e-03],\n",
              "                      [-4.4319e-02, -1.7752e-02,  7.8887e-04,  ...,  1.9521e-02,\n",
              "                        4.5109e-02,  1.1232e-01],\n",
              "                      [-9.9723e-03,  7.9488e-02,  1.8997e-02,  ...,  3.6016e-02,\n",
              "                       -2.3125e-02,  8.9477e-02],\n",
              "                      ...,\n",
              "                      [-5.0007e-08, -3.7025e-08, -7.5545e-08,  ..., -2.2442e-08,\n",
              "                       -3.1449e-08, -3.3532e-08],\n",
              "                      [-1.3276e-08, -1.1541e-08,  1.9463e-08,  ...,  1.9802e-08,\n",
              "                        4.3405e-08, -1.8405e-09],\n",
              "                      [ 7.3688e-02,  8.3731e-03,  9.0658e-04,  ...,  6.0736e-02,\n",
              "                       -6.1721e-02,  2.5403e-02]])),\n",
              "             ('dense4.bias',\n",
              "              tensor([-6.4641e-06, -1.5529e-04,  4.6773e-05,  1.7044e-05,  1.2783e-08,\n",
              "                      -6.1974e-05, -8.8598e-10,  4.5908e-05,  1.5532e-05, -7.0243e-06,\n",
              "                      -2.6747e-05,  3.2133e-05,  1.0068e-05,  2.0243e-05, -6.7878e-05,\n",
              "                      -5.9087e-06, -2.3214e-05, -2.8847e-05,  6.8476e-05,  2.4186e-05,\n",
              "                       4.6680e-05, -1.7497e-07, -5.8904e-05,  1.4478e-05,  7.6778e-05,\n",
              "                       1.4548e-05, -1.5919e-06, -8.0108e-06,  9.9210e-06,  2.7274e-07,\n",
              "                       8.4165e-05, -2.0497e-05, -1.8740e-05,  1.4130e-17, -1.5571e-05,\n",
              "                      -1.3749e-05,  5.9389e-05,  1.4427e-05,  7.7390e-05,  2.2668e-05,\n",
              "                       8.4596e-06, -6.3685e-05, -4.5795e-05,  5.5170e-06,  6.0317e-06,\n",
              "                       2.3144e-05, -1.3786e-05, -7.8229e-05,  2.8425e-05, -9.5880e-07,\n",
              "                       1.2577e-05, -1.8111e-05,  7.3510e-06, -2.2665e-07,  1.1440e-04,\n",
              "                      -6.2674e-07, -1.1269e-04, -1.9449e-06, -4.2160e-07,  2.3179e-05,\n",
              "                       2.4765e-06,  4.3826e-05,  2.2481e-05, -7.2240e-07, -6.9541e-07,\n",
              "                       1.5293e-05,  4.8742e-06,  1.8668e-05, -1.2762e-06, -9.0456e-06,\n",
              "                      -6.3351e-08, -6.0078e-07,  8.2178e-07,  3.1043e-05,  6.7265e-05,\n",
              "                       5.7585e-05,  9.0619e-06,  2.1058e-05,  2.7013e-05, -2.2078e-05,\n",
              "                       4.2830e-08,  7.0988e-09, -1.2092e-05, -4.1527e-06,  1.0075e-09,\n",
              "                      -4.4209e-05, -1.6103e-05,  5.0565e-05, -1.9580e-05, -3.3426e-05,\n",
              "                      -4.7933e-05,  3.0689e-05,  3.6502e-06, -4.0224e-07,  5.3950e-05,\n",
              "                      -1.6129e-06,  4.6394e-06, -2.7002e-05,  1.7112e-05,  5.3316e-06,\n",
              "                      -2.9105e-05,  2.1566e-05,  1.2614e-05,  1.9661e-06, -6.2872e-05,\n",
              "                       1.0267e-06, -1.4108e-07, -3.0749e-05, -1.7396e-05, -7.7555e-08,\n",
              "                       2.6662e-05,  3.1847e-06, -4.1827e-06, -5.4477e-06,  1.6297e-05,\n",
              "                       4.1702e-05,  4.1909e-06,  3.6595e-05,  5.3544e-05, -3.7917e-10,\n",
              "                      -5.0888e-06,  4.9974e-06,  2.3517e-05,  2.5746e-12,  4.9707e-06,\n",
              "                      -2.3421e-06, -1.3570e-06,  1.5745e-05, -1.5222e-05, -6.0881e-14,\n",
              "                      -1.9109e-04, -8.4255e-05,  1.7490e-06, -2.3449e-06,  3.5017e-05,\n",
              "                       1.6109e-06,  7.6007e-05,  1.4254e-05, -2.5618e-10, -6.3530e-06,\n",
              "                       1.1189e-05,  8.9558e-05, -4.9353e-06, -1.2612e-05,  2.6853e-05,\n",
              "                       1.6321e-05,  2.6049e-05, -1.0106e-05, -6.5221e-10,  1.3065e-04,\n",
              "                       1.0797e-05, -6.5245e-06,  5.6366e-07, -2.7782e-07,  4.7451e-05,\n",
              "                       1.4997e-13, -5.9781e-05, -3.6473e-05, -7.9385e-06,  1.9601e-06,\n",
              "                       7.7190e-06, -3.6658e-06,  1.5062e-05,  1.1401e-06, -1.5719e-05,\n",
              "                      -1.1094e-04, -1.0529e-05,  4.5496e-06, -1.4744e-05, -2.7178e-06,\n",
              "                      -4.4180e-12, -1.7827e-06, -4.9178e-06, -4.1294e-08, -4.6238e-05,\n",
              "                       6.2131e-06, -1.6677e-05, -2.5667e-06,  1.5256e-06, -3.2685e-05,\n",
              "                      -1.0718e-05, -2.3897e-06,  2.1067e-05, -3.8915e-06, -2.1953e-05,\n",
              "                       3.8704e-05,  1.7531e-06, -1.3717e-05,  5.9858e-05,  2.2933e-05,\n",
              "                       7.9890e-05, -1.0983e-06,  1.6197e-05,  4.3590e-06,  1.4997e-06,\n",
              "                      -2.4286e-05, -5.7552e-06, -3.7419e-05,  4.0312e-05,  1.1485e-04,\n",
              "                      -1.0314e-04,  4.9341e-06,  2.8839e-06, -6.8695e-07, -2.1815e-06,\n",
              "                       4.2873e-05,  8.5829e-06,  1.4270e-07, -2.5065e-05,  4.4525e-06,\n",
              "                      -5.5835e-08,  2.3107e-06,  3.4801e-05, -6.8070e-05, -1.3918e-05,\n",
              "                       2.3535e-05, -9.3069e-05, -8.3758e-08, -8.7411e-06, -8.9486e-06,\n",
              "                       2.3761e-05, -2.8193e-06, -1.4600e-05,  5.3267e-06, -1.9062e-06,\n",
              "                       3.6473e-05,  1.4388e-05, -1.0490e-04,  3.1162e-05, -4.9534e-07,\n",
              "                      -2.9070e-06, -6.3842e-06, -2.6627e-06, -9.7613e-07,  4.2007e-05,\n",
              "                       1.3443e-05, -2.2457e-05,  4.7317e-05,  1.4531e-04,  7.8827e-07,\n",
              "                      -1.2770e-05,  7.5227e-07, -1.8661e-05, -1.0590e-04,  1.5308e-05,\n",
              "                       5.7799e-06,  3.4274e-06, -2.3844e-05, -1.1656e-06, -1.0433e-05,\n",
              "                      -1.2069e-04, -1.0875e-06, -7.0474e-06,  4.8508e-12, -1.3844e-12,\n",
              "                      -7.0300e-05])),\n",
              "             ('batch_norm4.weight',\n",
              "              tensor([ 6.2596e-02,  3.5781e-01,  3.6235e-01,  1.5113e-01,  4.4802e-03,\n",
              "                       2.6755e-01,  2.1939e-03,  2.2284e-01,  3.4184e-01,  7.4767e-02,\n",
              "                       2.0578e-01,  1.8841e-01,  1.0234e-01,  2.4198e-01,  2.4138e-01,\n",
              "                       8.9702e-02,  1.3518e-01,  2.5452e-01,  3.6715e-01,  2.9006e-01,\n",
              "                       3.0241e-01,  2.1273e-02,  3.7125e-01,  1.8755e-01,  3.4316e-01,\n",
              "                       2.5470e-01,  3.9406e-02,  2.2254e-01,  7.0547e-02,  7.7262e-02,\n",
              "                       3.3736e-01,  2.1797e-01,  3.5148e-01,  2.3230e-11,  1.9631e-01,\n",
              "                       2.6394e-01,  2.3671e-01,  2.9152e-01,  2.3696e-01,  1.6983e-01,\n",
              "                       1.0448e-01,  2.5664e-01,  2.9464e-01,  1.1716e-01,  1.4888e-01,\n",
              "                       1.9306e-01,  1.7737e-01,  3.1012e-01,  1.7841e-01,  1.4274e-01,\n",
              "                       1.4168e-01,  2.5841e-01,  1.5089e-01,  1.5116e-02,  2.3643e-01,\n",
              "                       2.9177e-02,  3.5292e-01,  3.0377e-01,  2.6649e-02,  2.8971e-01,\n",
              "                       1.5020e-01,  3.2777e-01,  1.6136e-01,  6.6808e-02,  8.3452e-02,\n",
              "                       1.1979e-01,  1.7025e-01,  2.2942e-01,  2.1737e-01,  2.0452e-01,\n",
              "                       7.8351e-02,  1.2598e-01,  4.0799e-02,  2.4377e-01,  3.4987e-01,\n",
              "                       2.6064e-01,  1.0477e-01,  1.1783e-01,  1.9466e-01,  1.4532e-01,\n",
              "                       1.9987e-01,  2.4874e-03,  1.3467e-01,  6.8455e-02,  1.6922e-03,\n",
              "                       4.1110e-01,  1.7897e-01,  3.8389e-01,  3.5240e-01,  1.6213e-01,\n",
              "                       2.3135e-01,  2.8125e-01,  7.2161e-02,  1.7656e-02,  1.6682e-01,\n",
              "                       1.3153e-01,  1.7782e-01,  1.7981e-01,  1.8428e-01,  2.1237e-01,\n",
              "                       1.6711e-01,  2.9146e-01,  8.5762e-02,  8.0627e-02,  2.7201e-01,\n",
              "                       1.1137e-01,  6.6929e-02,  2.2656e-01,  2.6737e-01,  3.5184e-02,\n",
              "                       2.0932e-01,  1.9553e-01,  3.6990e-01,  2.1253e-01,  1.2166e-01,\n",
              "                       2.5255e-01,  6.8950e-02,  2.7251e-01,  2.0543e-01, -4.9014e-04,\n",
              "                       1.5235e-01,  1.0762e-01,  2.3351e-01, -2.8529e-05,  6.0123e-02,\n",
              "                       6.9977e-02,  1.4014e-01,  2.0481e-01,  3.0398e-01,  3.3920e-06,\n",
              "                       3.7715e-01,  3.4914e-01,  2.5688e-01,  1.0190e-01,  2.8073e-01,\n",
              "                       8.1155e-02,  2.6329e-01,  1.6867e-01, -1.6129e-04,  1.6449e-01,\n",
              "                       7.0939e-02,  2.8222e-01,  1.9996e-01,  2.0556e-01,  2.6289e-01,\n",
              "                       2.2814e-01,  3.1116e-01,  2.0172e-01,  4.1460e-04,  3.0632e-01,\n",
              "                       3.5599e-01,  4.9012e-02,  8.0927e-02,  1.8549e-02,  2.1952e-01,\n",
              "                      -8.3903e-07,  1.6887e-01,  1.9683e-01,  1.8090e-01,  1.2550e-01,\n",
              "                       2.0355e-01,  2.6347e-01,  1.6190e-01,  1.8338e-01,  1.6442e-01,\n",
              "                       1.8982e-01,  3.3914e-01,  1.2125e-01,  3.8131e-01,  2.4943e-01,\n",
              "                      -2.7282e-06,  1.1939e-01,  1.3970e-01,  1.5051e-02,  1.3615e-01,\n",
              "                       2.8928e-01,  1.6875e-01,  6.5879e-02,  9.2617e-02,  2.0242e-01,\n",
              "                       2.3437e-01,  8.1564e-02,  2.2998e-01,  5.1803e-02,  1.7505e-01,\n",
              "                       2.7211e-01,  1.1993e-01,  1.3864e-01,  3.2185e-01,  2.7240e-01,\n",
              "                       3.9047e-01,  2.7957e-02,  1.6389e-01,  1.0995e-01,  5.0994e-02,\n",
              "                       1.8681e-01,  2.0189e-01,  2.4737e-01,  2.1235e-01,  3.0552e-01,\n",
              "                       3.3475e-01,  2.3979e-01,  1.9828e-01,  5.8212e-02,  8.7958e-02,\n",
              "                       2.8706e-01,  1.4064e-01,  6.2237e-02,  1.7807e-01,  7.7309e-02,\n",
              "                       4.0193e-03,  1.6942e-01,  2.5812e-01,  2.8881e-01,  1.6141e-01,\n",
              "                       1.8934e-01,  3.2592e-01,  2.6776e-02,  2.9151e-01,  1.7002e-01,\n",
              "                       2.4168e-01,  1.4233e-01,  1.6795e-01,  3.9385e-01,  1.2839e-01,\n",
              "                       2.5164e-01,  9.0897e-02,  2.7631e-01,  2.5586e-01,  2.8612e-02,\n",
              "                       2.9743e-01,  2.4836e-01,  2.6600e-01,  9.6623e-02,  1.8526e-01,\n",
              "                       2.3046e-01,  2.1962e-01,  2.3025e-01,  2.5920e-01,  1.8874e-02,\n",
              "                       3.1538e-01,  1.6361e-01,  2.8450e-01,  3.4799e-01,  2.5775e-01,\n",
              "                       3.4449e-01,  9.5603e-02,  1.8996e-01,  4.8305e-02,  2.7283e-01,\n",
              "                       3.3871e-01,  1.7326e-01,  8.7740e-02, -8.8415e-06,  1.0026e-06,\n",
              "                       3.0609e-01])),\n",
              "             ('batch_norm4.bias',\n",
              "              tensor([-1.1714e-02, -2.4985e-01, -3.5665e-01, -1.6436e-01, -7.7776e-03,\n",
              "                      -3.5135e-01, -5.4015e-03, -2.5942e-01, -3.7342e-01, -2.8531e-02,\n",
              "                      -7.1707e-02, -1.1096e-01, -3.6424e-02, -8.8176e-02, -9.4747e-02,\n",
              "                       1.6832e-02, -3.3032e-02, -2.5592e-02, -1.7892e-01, -3.4849e-01,\n",
              "                      -1.2069e-01, -3.4234e-02, -3.9342e-01, -1.2048e-01, -4.3396e-01,\n",
              "                      -2.5649e-01,  1.8661e-02, -7.0811e-02, -1.1165e-02, -9.8850e-02,\n",
              "                      -1.6638e-01, -3.9667e-01, -1.4933e-01, -2.4467e-04, -9.0656e-02,\n",
              "                      -1.0239e-01, -6.2525e-02, -1.8217e-01, -5.3273e-02, -1.5985e-01,\n",
              "                      -4.9552e-02, -1.3226e-01, -1.3681e-01, -9.7787e-02, -1.3177e-01,\n",
              "                      -9.7195e-02, -6.5185e-02, -2.1407e-01, -1.0465e-01, -4.2336e-02,\n",
              "                      -1.1210e-01, -8.6048e-02, -1.5008e-01, -2.7084e-02, -8.4433e-02,\n",
              "                      -3.7326e-02, -2.7521e-01, -8.9725e-02, -3.1879e-02, -2.6413e-01,\n",
              "                      -1.1819e-01, -5.1796e-01, -7.6617e-02, -1.1301e-01, -2.7717e-02,\n",
              "                      -4.7353e-02, -8.1284e-02, -6.2386e-02, -1.1700e-01, -4.9339e-02,\n",
              "                      -1.0967e-01, -1.6812e-01, -8.0518e-03, -6.9983e-02, -3.9150e-01,\n",
              "                      -2.2430e-01, -6.7370e-02, -6.1381e-02, -8.3911e-02, -4.0437e-02,\n",
              "                      -1.0361e-01, -3.5617e-03, -8.1626e-02, -6.4196e-03, -5.9116e-03,\n",
              "                      -2.9196e-01, -7.2139e-02, -3.6825e-01, -2.9817e-01, -1.1211e-01,\n",
              "                      -9.5410e-02, -9.4899e-02, -5.1806e-02, -2.9780e-02, -4.8123e-02,\n",
              "                      -2.8086e-02, -1.5785e-01, -1.9260e-01, -2.3586e-01, -4.6719e-02,\n",
              "                      -5.3547e-02, -1.6432e-01, -1.9145e-02, -2.8229e-02, -9.8049e-02,\n",
              "                      -1.3251e-01,  2.0316e-02, -1.2794e-01, -2.6601e-01, -4.3928e-02,\n",
              "                      -2.0164e-01, -8.0432e-02, -4.7061e-01, -2.0168e-01, -1.3425e-01,\n",
              "                      -1.8869e-01, -2.5871e-02, -4.8942e-02, -2.7938e-01, -1.9433e-03,\n",
              "                      -2.1227e-01, -8.9703e-02, -1.2016e-01, -7.8604e-03,  1.6514e-02,\n",
              "                      -5.0882e-02, -1.1583e-01, -1.2848e-01, -5.0733e-01, -2.1082e-04,\n",
              "                      -4.1692e-01, -2.7572e-01, -1.5008e-01, -6.0456e-02, -3.0271e-01,\n",
              "                      -1.2726e-01, -2.1524e-01, -1.2315e-01, -8.4063e-03, -6.7874e-02,\n",
              "                      -1.7819e-02, -2.6290e-01, -1.4360e-01, -1.1667e-01, -2.1558e-01,\n",
              "                      -7.6542e-02, -3.8699e-01, -7.8238e-02, -1.5071e-02, -2.0067e-01,\n",
              "                      -1.4188e-01, -3.2671e-03, -1.0005e-01, -3.0535e-02, -8.1638e-02,\n",
              "                      -8.3316e-04, -2.0498e-02, -1.7461e-01, -1.9388e-01, -3.6275e-02,\n",
              "                      -6.5900e-02, -1.7132e-01, -7.6649e-02, -7.5315e-02, -2.4288e-01,\n",
              "                      -4.6428e-02, -2.5415e-01, -5.5660e-02, -4.4244e-01, -4.0932e-02,\n",
              "                      -3.3089e-03, -4.7448e-02, -5.2670e-02, -3.0679e-02, -4.5547e-02,\n",
              "                      -5.2313e-01, -8.7123e-02, -9.1319e-02, -8.2997e-02, -1.8498e-01,\n",
              "                      -9.0958e-02, -5.5874e-02, -4.2974e-02, -3.4651e-02, -1.6952e-01,\n",
              "                      -1.5415e-01, -5.7633e-02, -6.4550e-02, -3.6911e-01, -2.4057e-01,\n",
              "                      -2.7488e-01,  7.3918e-03, -1.1393e-01, -1.0463e-01, -2.7278e-02,\n",
              "                      -5.2081e-02, -7.8158e-02, -1.3919e-01, -1.0833e-01, -2.2271e-01,\n",
              "                      -4.3040e-01, -1.8054e-01, -9.4704e-02, -6.5783e-02, -4.9558e-02,\n",
              "                      -2.5468e-01, -1.7132e-01, -6.7142e-02, -1.3854e-02, -8.4740e-02,\n",
              "                      -4.3735e-03, -2.4337e-01, -3.0668e-01, -6.1721e-02, -1.3923e-01,\n",
              "                      -2.1332e-02, -3.4012e-01, -9.8252e-03, -1.2908e-01, -2.8684e-02,\n",
              "                      -1.4179e-01, -1.0554e-01, -4.2310e-02, -2.3687e-01, -1.6220e-01,\n",
              "                      -2.2909e-01,  1.2983e-02, -4.1169e-01, -3.8173e-01, -2.7574e-02,\n",
              "                      -2.4348e-01, -2.8134e-02, -9.8383e-02, -1.6291e-01, -9.3602e-02,\n",
              "                      -2.4192e-01, -8.8177e-02, -6.1260e-02, -3.6846e-01, -2.6892e-03,\n",
              "                      -5.2112e-01, -2.1404e-01, -4.7972e-02, -3.4055e-01, -6.4974e-02,\n",
              "                      -2.1979e-01, -2.0551e-02, -1.1930e-01, -4.4773e-02, -9.7409e-02,\n",
              "                      -2.3384e-01, -7.2644e-02, -4.0821e-02, -2.2448e-03, -1.7199e-04,\n",
              "                      -2.1728e-01])),\n",
              "             ('batch_norm4.running_mean',\n",
              "              tensor([-1.6828e-02, -5.0973e-02, -3.4363e-02, -1.5748e-02, -1.4563e-04,\n",
              "                      -4.0867e-02,  2.5049e-06, -4.6854e-02, -5.6167e-02, -1.8530e-02,\n",
              "                      -4.0272e-02, -3.2197e-02, -3.8964e-03, -4.2815e-02, -6.4476e-02,\n",
              "                      -2.0136e-02, -2.0100e-02, -4.5580e-02, -3.6961e-02, -3.3909e-02,\n",
              "                      -2.2731e-02, -4.9377e-04, -6.5404e-02, -2.2346e-02, -4.1818e-02,\n",
              "                      -1.6151e-02, -1.4663e-02, -2.5829e-02, -1.1136e-02, -7.4590e-03,\n",
              "                      -4.3532e-02, -8.6353e-03, -3.6329e-02, -3.0917e-14, -2.8916e-02,\n",
              "                      -1.7708e-02, -3.2013e-02, -2.8904e-02, -5.6139e-02, -1.5147e-02,\n",
              "                      -5.3493e-03, -4.9083e-02, -5.4466e-02, -1.5353e-02, -2.1326e-02,\n",
              "                      -1.8232e-02, -1.9088e-02, -7.3058e-02, -2.6417e-02, -2.1188e-02,\n",
              "                      -1.7854e-02, -5.6086e-03,  1.6069e-03,  1.4516e-03, -4.8078e-02,\n",
              "                      -4.5421e-03, -5.4948e-02,  1.8973e-02, -2.3212e-03, -3.2823e-02,\n",
              "                      -3.1095e-02, -3.1931e-02, -4.0349e-02,  7.9133e-04, -2.0591e-02,\n",
              "                      -2.6548e-02, -1.9475e-02, -2.8120e-02, -2.0400e-02, -3.9306e-02,\n",
              "                      -1.0443e-02, -2.1491e-03, -6.1945e-03, -2.8155e-02, -5.5445e-02,\n",
              "                      -6.2454e-02, -4.1167e-03, -1.9080e-02, -2.3039e-02, -2.7832e-02,\n",
              "                      -2.6523e-02,  1.2130e-05, -3.1478e-02, -1.3703e-02, -3.6014e-06,\n",
              "                      -5.9894e-02, -3.6337e-02, -4.0875e-02, -5.3752e-02, -4.0832e-03,\n",
              "                      -4.0633e-02, -5.3073e-02,  4.2007e-03, -1.0747e-03, -3.7528e-02,\n",
              "                      -2.2926e-02, -1.2553e-02, -3.9052e-02, -2.3150e-02, -3.3873e-02,\n",
              "                      -2.5823e-02, -4.8672e-02, -2.0181e-02, -2.0198e-02,  1.0992e-02,\n",
              "                      -9.7673e-03, -1.5282e-02, -5.6624e-02, -4.2901e-02,  8.6311e-04,\n",
              "                      -3.8186e-02, -8.8235e-03, -2.6702e-02, -3.0205e-02, -1.5374e-02,\n",
              "                      -3.9549e-02, -2.1479e-02, -4.7090e-02, -1.0957e-02, -2.9149e-06,\n",
              "                      -3.2775e-02, -1.1520e-02, -4.4194e-02,  2.1413e-07, -1.8137e-02,\n",
              "                      -3.8749e-03, -1.5598e-02, -1.8244e-02,  3.8806e-03,  2.8595e-09,\n",
              "                      -4.2859e-02, -5.0305e-02, -5.7046e-02, -3.7360e-03, -5.0314e-02,\n",
              "                      -1.1681e-02, -5.9533e-02, -1.5724e-02,  3.0483e-06, -1.0598e-02,\n",
              "                      -1.2360e-02, -4.8676e-02, -3.0571e-02, -3.5186e-02, -4.3548e-02,\n",
              "                      -4.3985e-02,  2.5252e-02, -3.3663e-02,  3.0295e-04, -5.4752e-02,\n",
              "                      -6.7985e-02, -1.2716e-02,  1.4791e-03,  8.3688e-04, -1.8611e-02,\n",
              "                       3.9294e-09, -4.7257e-02, -3.0944e-02, -3.5002e-02, -1.7243e-02,\n",
              "                      -3.1353e-02, -4.6282e-02, -9.0819e-03, -2.0949e-02, -2.0706e-02,\n",
              "                      -4.6130e-02, -5.7923e-02, -2.0430e-02, -6.4476e-02, -5.0298e-02,\n",
              "                       8.3406e-08, -1.1578e-02, -2.4395e-02, -3.1576e-04, -3.6438e-02,\n",
              "                       1.7734e-02, -4.0361e-02,  6.6194e-03, -1.0691e-02, -1.4732e-02,\n",
              "                      -2.3797e-02, -2.0608e-02, -3.6930e-02, -1.4221e-02, -3.7418e-02,\n",
              "                      -5.6087e-02, -1.4126e-02, -2.2330e-02, -4.5459e-02, -2.1027e-02,\n",
              "                      -5.6272e-02, -4.8066e-03, -2.2001e-02, -2.2060e-02, -1.9298e-03,\n",
              "                      -1.1627e-02, -1.2944e-02, -2.1811e-02, -4.0505e-02, -4.5254e-02,\n",
              "                      -2.7809e-02, -2.8350e-02, -2.1020e-02, -6.0503e-03, -1.4351e-03,\n",
              "                      -5.7067e-02, -8.9517e-03,  5.6719e-03, -2.5851e-02, -8.4143e-03,\n",
              "                      -6.4003e-03,  5.3386e-03, -1.7597e-02, -4.9435e-02, -1.6339e-02,\n",
              "                      -3.2120e-02, -6.3795e-02,  2.3649e-03, -5.7260e-02, -3.0661e-02,\n",
              "                      -2.2926e-02, -3.2760e-02, -2.3119e-02, -3.5599e-02,  6.6353e-03,\n",
              "                      -2.2775e-02, -1.7921e-02, -3.4446e-02, -2.3625e-02,  4.5368e-03,\n",
              "                      -5.3134e-02, -3.0628e-02, -4.2778e-02, -3.0164e-04, -5.5703e-02,\n",
              "                      -3.3912e-02, -2.2549e-02, -3.1250e-02, -3.8399e-02,  2.4322e-03,\n",
              "                      -1.7928e-02, -2.0029e-02, -4.6386e-02, -7.6654e-02, -3.2720e-02,\n",
              "                      -5.0035e-02, -1.1737e-02, -4.1751e-03,  4.7479e-03, -6.0172e-03,\n",
              "                      -7.6780e-02, -2.9113e-02, -1.2512e-02,  6.3369e-08, -1.7232e-08,\n",
              "                      -5.7112e-02])),\n",
              "             ('batch_norm4.running_var',\n",
              "              tensor([1.0003e-03, 7.5202e-03, 5.4489e-03, 2.2343e-03, 7.5689e-08, 4.1075e-03,\n",
              "                      4.2358e-09, 3.9754e-03, 6.8580e-03, 7.3290e-04, 3.7491e-03, 3.7752e-03,\n",
              "                      1.9561e-03, 5.3841e-03, 4.8201e-03, 1.8849e-03, 2.1779e-03, 6.8995e-03,\n",
              "                      7.4051e-03, 4.7681e-03, 5.2235e-03, 1.3577e-04, 6.1406e-03, 4.0033e-03,\n",
              "                      6.6779e-03, 5.4257e-03, 1.4238e-03, 5.2832e-03, 1.1418e-03, 7.1403e-04,\n",
              "                      7.5074e-03, 4.3919e-03, 6.2680e-03, 2.4066e-25, 4.0425e-03, 4.9905e-03,\n",
              "                      6.2548e-03, 5.3234e-03, 7.5504e-03, 2.2299e-03, 1.8548e-03, 6.2248e-03,\n",
              "                      4.8755e-03, 1.5645e-03, 2.4817e-03, 3.9230e-03, 4.0940e-03, 6.1694e-03,\n",
              "                      4.0015e-03, 3.3924e-03, 2.6220e-03, 6.0368e-03, 3.0905e-03, 1.7488e-04,\n",
              "                      6.0387e-03, 3.1520e-04, 6.4820e-03, 5.3277e-03, 2.0905e-04, 4.0921e-03,\n",
              "                      3.2326e-03, 4.9161e-03, 3.3077e-03, 1.0393e-03, 1.4377e-03, 1.6963e-03,\n",
              "                      2.5467e-03, 4.6092e-03, 3.8470e-03, 4.0594e-03, 7.8998e-04, 2.4979e-03,\n",
              "                      3.5987e-04, 4.8557e-03, 5.4970e-03, 5.2940e-03, 1.9716e-03, 2.0794e-03,\n",
              "                      3.9705e-03, 2.5082e-03, 5.1427e-03, 5.6155e-09, 2.1706e-03, 9.6723e-04,\n",
              "                      1.6804e-09, 7.4568e-03, 3.5461e-03, 5.6732e-03, 4.8470e-03, 2.6348e-03,\n",
              "                      5.0662e-03, 5.8954e-03, 9.2755e-04, 1.2590e-04, 3.0522e-03, 3.1205e-03,\n",
              "                      3.9245e-03, 3.9725e-03, 3.0518e-03, 3.4187e-03, 3.4004e-03, 6.7085e-03,\n",
              "                      1.2386e-03, 8.6220e-04, 4.7339e-03, 9.7832e-04, 1.4861e-03, 3.8594e-03,\n",
              "                      4.1430e-03, 5.1675e-04, 4.3318e-03, 3.5844e-03, 5.7601e-03, 3.5932e-03,\n",
              "                      1.6305e-03, 4.6945e-03, 1.2120e-03, 8.9536e-03, 3.7406e-03, 1.7358e-10,\n",
              "                      3.4382e-03, 1.5263e-03, 6.0738e-03, 4.9380e-12, 1.2350e-03, 6.6321e-04,\n",
              "                      2.7684e-03, 3.8151e-03, 5.4409e-03, 2.7882e-15, 6.6359e-03, 7.1048e-03,\n",
              "                      6.4851e-03, 1.3328e-03, 5.1500e-03, 9.9237e-04, 4.8840e-03, 1.6099e-03,\n",
              "                      4.3057e-08, 3.8344e-03, 1.0420e-03, 5.7255e-03, 4.6515e-03, 3.8969e-03,\n",
              "                      5.3355e-03, 5.1756e-03, 5.1763e-03, 5.9605e-03, 1.1421e-06, 4.4917e-03,\n",
              "                      8.5941e-03, 7.6713e-04, 1.1701e-03, 1.7341e-04, 3.8437e-03, 6.0549e-16,\n",
              "                      4.3749e-03, 2.8390e-03, 3.5083e-03, 2.1206e-03, 3.4883e-03, 5.3888e-03,\n",
              "                      2.3306e-03, 3.7526e-03, 2.7670e-03, 5.4676e-03, 8.9711e-03, 2.4866e-03,\n",
              "                      7.2154e-03, 7.4339e-03, 5.4209e-14, 1.9129e-03, 2.7398e-03, 5.9100e-05,\n",
              "                      3.1864e-03, 5.4153e-03, 4.1232e-03, 1.1455e-03, 1.1164e-03, 1.4385e-03,\n",
              "                      5.5755e-03, 1.1179e-03, 6.0352e-03, 4.5169e-04, 2.2093e-03, 6.6860e-03,\n",
              "                      2.4994e-03, 1.7841e-03, 5.5070e-03, 4.1195e-03, 8.2816e-03, 4.9773e-04,\n",
              "                      2.4721e-03, 1.1311e-03, 4.2718e-04, 2.8864e-03, 3.4357e-03, 4.4706e-03,\n",
              "                      4.7127e-03, 5.7418e-03, 5.8580e-03, 4.6349e-03, 3.4714e-03, 6.9570e-04,\n",
              "                      7.8685e-04, 5.5657e-03, 1.3584e-03, 8.8614e-04, 4.0410e-03, 5.2597e-04,\n",
              "                      1.0623e-04, 2.8039e-03, 4.2466e-03, 6.1854e-03, 1.8979e-03, 4.8099e-03,\n",
              "                      6.0444e-03, 1.0514e-04, 6.3440e-03, 2.6338e-03, 5.5699e-03, 2.5172e-03,\n",
              "                      3.4214e-03, 8.4769e-03, 1.3850e-03, 5.6629e-03, 2.5819e-03, 5.2232e-03,\n",
              "                      5.2472e-03, 2.7920e-04, 6.0539e-03, 5.8529e-03, 5.2818e-03, 2.0404e-03,\n",
              "                      4.4614e-03, 3.0604e-03, 4.4429e-03, 5.1072e-03, 5.4420e-03, 1.1720e-04,\n",
              "                      6.0276e-03, 2.9002e-03, 7.6864e-03, 8.1307e-03, 5.5635e-03, 7.5926e-03,\n",
              "                      1.6173e-03, 2.8681e-03, 3.7147e-04, 6.1654e-03, 7.8239e-03, 2.3514e-03,\n",
              "                      1.6003e-03, 5.7517e-14, 4.0183e-14, 7.4210e-03])),\n",
              "             ('batch_norm4.num_batches_tracked', tensor(7296)),\n",
              "             ('dense5.weight',\n",
              "              tensor([[ 5.3219e-03, -6.0719e-04, -3.0836e-03,  ..., -2.8644e-04,\n",
              "                        3.2142e-03,  1.7530e-01],\n",
              "                      [ 6.2974e-02, -4.9767e-03, -7.9695e-02,  ...,  5.1166e-04,\n",
              "                        3.1692e-03,  5.5013e-02],\n",
              "                      [ 5.5151e-02, -2.5666e-02, -4.2474e-02,  ...,  6.8927e-05,\n",
              "                       -3.5176e-03,  6.1229e-02],\n",
              "                      [ 2.5178e-02, -3.9096e-02, -5.5226e-02,  ..., -4.6849e-03,\n",
              "                       -2.8063e-03,  1.4028e-01],\n",
              "                      [-3.1132e-02, -2.1725e-02, -1.3553e-02,  ...,  4.5471e-03,\n",
              "                        1.6473e-03,  1.7811e-01]])),\n",
              "             ('dense5.bias',\n",
              "              tensor([-0.0104, -0.0213, -0.0028, -0.0044, -0.0127])),\n",
              "             ('PReLU.weight', tensor([0.2500]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghz5mOom7h3V"
      },
      "source": [
        "# model2.weight\r\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFsvC6fP3TnK"
      },
      "source": [
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.data import random_split\r\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2YJw-UW59AM"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIyMov452uJP"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmUYls021OdI"
      },
      "source": [
        "dataset = MNIST(root='data/', download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LEknvJQ2DQB"
      },
      "source": [
        "dataset = MNIST(root='data/', train=True, transform= transforms.ToTensor() )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "o8PpcsfZ19i5",
        "outputId": "203f133a-df6c-405e-9fc6-317da88a13d4"
      },
      "source": [
        "image, label= dataset[0]\r\n",
        "plt.imshow(image.reshape(28,28), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f57973b6748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN9klEQVR4nO3df4xV9ZnH8c+zWP6QojBrOhKKSyEGg8ZON4gbl6w1hvojGhw1TSexoZE4/YNJaLIhNewf1WwwZBU2SzTNTKMWNl1qEzUgaQouoOzGhDgiKo5LdQ2mTEaowZEf/mCHefaPezBTnfu9w7nn3nOZ5/1Kbu6957nnnicnfDi/7pmvubsATH5/VXYDAJqDsANBEHYgCMIOBEHYgSAuaubCzIxT/0CDubuNN72uLbuZ3Wpmh8zsPTN7sJ7vAtBYlvc6u5lNkfRHSUslHZH0qqQudx9IzMOWHWiwRmzZF0t6z93fd/czkn4raVkd3weggeoJ+2xJfxrz/kg27S+YWbeZ9ZtZfx3LAlCnhp+gc/c+SX0Su/FAmerZsg9KmjPm/bezaQBaUD1hf1XSlWb2HTObKulHkrYV0xaAouXejXf3ETPrkbRD0hRJT7n724V1BqBQuS+95VoYx+xAwzXkRzUALhyEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBJF7yGZcGKZMmZKsX3rppQ1dfk9PT9XaxRdfnJx3wYIFyfrKlSuT9ccee6xqraurKznv559/nqyvW7cuWX/44YeT9TLUFXYzOyzppKSzkkbcfVERTQEoXhFb9pvc/aMCvgdAA3HMDgRRb9hd0k4ze83Musf7gJl1m1m/mfXXuSwAdah3N36Juw+a2bckvWhm/+Pue8d+wN37JPVJkpl5ncsDkFNdW3Z3H8yej0l6XtLiIpoCULzcYTezaWY2/dxrST+QdLCoxgAUq57d+HZJz5vZue/5D3f/QyFdTTJXXHFFsj516tRk/YYbbkjWlyxZUrU2Y8aM5Lz33HNPsl6mI0eOJOsbN25M1js7O6vWTp48mZz3jTfeSNZffvnlZL0V5Q67u78v6bsF9gKggbj0BgRB2IEgCDsQBGEHgiDsQBDm3rwftU3WX9B1dHQk67t3707WG32baasaHR1N1u+///5k/dSpU7mXPTQ0lKx//PHHyfqhQ4dyL7vR3N3Gm86WHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeC4Dp7Adra2pL1ffv2Jevz5s0rsp1C1ep9eHg4Wb/pppuq1s6cOZOcN+rvD+rFdXYgOMIOBEHYgSAIOxAEYQeCIOxAEIQdCIIhmwtw/PjxZH316tXJ+h133JGsv/7668l6rT+pnHLgwIFkfenSpcn66dOnk/Wrr766am3VqlXJeVEstuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EAT3s7eASy65JFmvNbxwb29v1dqKFSuS8953333J+pYtW5J1tJ7c97Ob2VNmdszMDo6Z1mZmL5rZu9nzzCKbBVC8iezG/1rSrV+Z9qCkXe5+paRd2XsALaxm2N19r6Sv/h50maRN2etNku4quC8ABcv72/h2dz83WNaHktqrfdDMuiV151wOgILUfSOMu3vqxJu790nqkzhBB5Qp76W3o2Y2S5Ky52PFtQSgEfKGfZuk5dnr5ZK2FtMOgEapuRtvZlskfV/SZWZ2RNIvJK2T9DszWyHpA0k/bGSTk92JEyfqmv+TTz7JPe8DDzyQrD/zzDPJeq0x1tE6aobd3buqlG4uuBcADcTPZYEgCDsQBGEHgiDsQBCEHQiCW1wngWnTplWtvfDCC8l5b7zxxmT9tttuS9Z37tyZrKP5GLIZCI6wA0EQdiAIwg4EQdiBIAg7EARhB4LgOvskN3/+/GR9//79yfrw8HCyvmfPnmS9v7+/au2JJ55IztvMf5uTCdfZgeAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIrrMH19nZmaw//fTTyfr06dNzL3vNmjXJ+ubNm5P1oaGhZD0qrrMDwRF2IAjCDgRB2IEgCDsQBGEHgiDsQBBcZ0fSNddck6xv2LAhWb/55vyD/fb29ibra9euTdYHBwdzL/tClvs6u5k9ZWbHzOzgmGkPmdmgmR3IHrcX2SyA4k1kN/7Xkm4dZ/q/untH9vh9sW0BKFrNsLv7XknHm9ALgAaq5wRdj5m9me3mz6z2ITPrNrN+M6v+x8gANFzesP9S0nxJHZKGJK2v9kF373P3Re6+KOeyABQgV9jd/ai7n3X3UUm/krS42LYAFC1X2M1s1pi3nZIOVvssgNZQ8zq7mW2R9H1Jl0k6KukX2fsOSS7psKSfunvNm4u5zj75zJgxI1m/8847q9Zq3StvNu7l4i/t3r07WV+6dGmyPllVu85+0QRm7Bpn8pN1dwSgqfi5LBAEYQeCIOxAEIQdCIKwA0FwiytK88UXXyTrF12Uvlg0MjKSrN9yyy1Vay+99FJy3gsZf0oaCI6wA0EQdiAIwg4EQdiBIAg7EARhB4KoedcbYrv22muT9XvvvTdZv+6666rWal1Hr2VgYCBZ37t3b13fP9mwZQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBILjOPsktWLAgWe/p6UnW77777mT98ssvP++eJurs2bPJ+tBQ+q+Xj46OFtnOBY8tOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwXX2C0Cta9ldXeMNtFtR6zr63Llz87RUiP7+/mR97dq1yfq2bduKbGfSq7llN7M5ZrbHzAbM7G0zW5VNbzOzF83s3ex5ZuPbBZDXRHbjRyT9o7svlPR3klaa2UJJD0ra5e5XStqVvQfQomqG3d2H3H1/9vqkpHckzZa0TNKm7GObJN3VqCYB1O+8jtnNbK6k70naJ6nd3c/9OPlDSe1V5umW1J2/RQBFmPDZeDP7pqRnJf3M3U+MrXlldMhxB2109z53X+Tui+rqFEBdJhR2M/uGKkH/jbs/l00+amazsvosScca0yKAItTcjTczk/SkpHfcfcOY0jZJyyWty563NqTDSaC9fdwjnC8tXLgwWX/88ceT9auuuuq8eyrKvn37kvVHH320am3r1vQ/GW5RLdZEjtn/XtKPJb1lZgeyaWtUCfnvzGyFpA8k/bAxLQIoQs2wu/t/Sxp3cHdJNxfbDoBG4eeyQBCEHQiCsANBEHYgCMIOBMEtrhPU1tZWtdbb25uct6OjI1mfN29erp6K8MorryTr69evT9Z37NiRrH/22Wfn3RMagy07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgQR5jr79ddfn6yvXr06WV+8eHHV2uzZs3P1VJRPP/20am3jxo3JeR955JFk/fTp07l6Quthyw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQYS5zt7Z2VlXvR4DAwPJ+vbt25P1kZGRZD11z/nw8HByXsTBlh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgjB3T3/AbI6kzZLaJbmkPnf/NzN7SNIDkv6cfXSNu/++xnelFwagbu4+7qjLEwn7LEmz3H2/mU2X9Jqku1QZj/2Uuz820SYIO9B41cI+kfHZhyQNZa9Pmtk7ksr90ywAztt5HbOb2VxJ35O0L5vUY2ZvmtlTZjazyjzdZtZvZv11dQqgLjV347/8oNk3Jb0saa27P2dm7ZI+UuU4/p9V2dW/v8Z3sBsPNFjuY3ZJMrNvSNouaYe7bxinPlfSdne/psb3EHagwaqFveZuvJmZpCclvTM26NmJu3M6JR2st0kAjTORs/FLJP2XpLckjWaT10jqktShym78YUk/zU7mpb6LLTvQYHXtxheFsAONl3s3HsDkQNiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQii2UM2fyTpgzHvL8umtaJW7a1V+5LoLa8ie/ubaoWm3s/+tYWb9bv7otIaSGjV3lq1L4ne8mpWb+zGA0EQdiCIssPeV/LyU1q1t1btS6K3vJrSW6nH7ACap+wtO4AmIexAEKWE3cxuNbNDZvaemT1YRg/VmNlhM3vLzA6UPT5dNobeMTM7OGZam5m9aGbvZs/jjrFXUm8Pmdlgtu4OmNntJfU2x8z2mNmAmb1tZquy6aWuu0RfTVlvTT9mN7Mpkv4oaamkI5JeldTl7gNNbaQKMzssaZG7l/4DDDP7B0mnJG0+N7SWmf2LpOPuvi77j3Kmu/+8RXp7SOc5jHeDeqs2zPhPVOK6K3L48zzK2LIvlvSeu7/v7mck/VbSshL6aHnuvlfS8a9MXiZpU/Z6kyr/WJquSm8twd2H3H1/9vqkpHPDjJe67hJ9NUUZYZ8t6U9j3h9Ra4337pJ2mtlrZtZddjPjaB8zzNaHktrLbGYcNYfxbqavDDPeMusuz/Dn9eIE3dctcfe/lXSbpJXZ7mpL8soxWCtdO/2lpPmqjAE4JGl9mc1kw4w/K+ln7n5ibK3MdTdOX01Zb2WEfVDSnDHvv51NawnuPpg9H5P0vCqHHa3k6LkRdLPnYyX38yV3P+ruZ919VNKvVOK6y4YZf1bSb9z9uWxy6etuvL6atd7KCPurkq40s++Y2VRJP5K0rYQ+vsbMpmUnTmRm0yT9QK03FPU2Scuz18slbS2xl7/QKsN4VxtmXCWvu9KHP3f3pj8k3a7KGfn/lfRPZfRQpa95kt7IHm+X3ZukLars1v2fKuc2Vkj6a0m7JL0r6T8ltbVQb/+uytDeb6oSrFkl9bZElV30NyUdyB63l73uEn01Zb3xc1kgCE7QAUEQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNGbNWSv4Swi"
      },
      "source": [
        "train_ds, valid_ds= random_split(dataset, [50000, 10000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRz-uX9X4bbC",
        "outputId": "7392c444-b827-41a1-b624-b7b845f64614"
      },
      "source": [
        "len(valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJIVGOSe4grC"
      },
      "source": [
        "train_loader= DataLoader(train_ds, batch_size= 128, shuffle=True)\r\n",
        "valid_loader= DataLoader(valid_ds, batch_size= 128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHa2nSQD6AyD"
      },
      "source": [
        "model= nn.Linear(28*28, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llsUToo66Wm5",
        "outputId": "fd870515-132b-4d07-d514-6e906e84605d"
      },
      "source": [
        "model.weight.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjEB2zEoLKqa"
      },
      "source": [
        "input_size=28*28\r\n",
        "num_classes=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzEENKviKxFc"
      },
      "source": [
        "class MnistModel(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.linear = nn.Linear(input_size, num_classes)\r\n",
        "        \r\n",
        "    def forward(self, xb):\r\n",
        "        xb = xb.reshape(-1, 784)\r\n",
        "        out = self.linear(xb)\r\n",
        "        return out\r\n",
        "model= MnistModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvEks1gPOL9V",
        "outputId": "9ccb4f89-5502-444d-b26a-cc421f95f802"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.0290, -0.0213,  0.0100,  ..., -0.0061,  0.0109,  0.0099],\n",
              "         [ 0.0217, -0.0259, -0.0179,  ..., -0.0297, -0.0054, -0.0094],\n",
              "         [ 0.0307,  0.0037,  0.0141,  ...,  0.0268, -0.0144, -0.0299],\n",
              "         ...,\n",
              "         [ 0.0135, -0.0005, -0.0156,  ...,  0.0219, -0.0227,  0.0009],\n",
              "         [-0.0056,  0.0209,  0.0290,  ...,  0.0196,  0.0009, -0.0293],\n",
              "         [-0.0187, -0.0308, -0.0286,  ..., -0.0213, -0.0078,  0.0231]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-0.0182,  0.0234, -0.0184,  0.0082,  0.0191,  0.0273,  0.0133,  0.0202,\n",
              "          0.0199,  0.0145], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEb4W6BNX_EL"
      },
      "source": [
        "def fit(lr,num_epochs, model, trainloader, val_loader, opt_func=torch.optim.SGD ):\r\n",
        "  \r\n",
        "  opt_func=torch.optim.SGD\r\n",
        "  optimizer = opt_func(model.parameters(), lr)\r\n",
        "\r\n",
        "  record=[]\r\n",
        "\r\n",
        "  for num_epoch in range(num_epochs):\r\n",
        "      for batch in train_loader:\r\n",
        "        images, label = batch\r\n",
        "        out = model(images)\r\n",
        "        loss =  F.cross_entropy(out, label)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "      for batch in valid_loader:\r\n",
        "        images, labels = batch\r\n",
        "        out = model(images)\r\n",
        "        loss =  F.cross_entropy(out, labels)\r\n",
        "        _ , preds = torch.max(F.softmax(out, dim=1) ,dim=1)\r\n",
        "        accuracy = torch.tensor(torch.sum(preds == labels).item() / len(preds))\r\n",
        "\r\n",
        "      record.append(accuracy)\r\n",
        "      print('Num of epoch: {}, Loss:{} , Accuracy:{}' .format(num_epoch,loss, accuracy))\r\n",
        "  \r\n",
        "  return record\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J1nvLbblkbi"
      },
      "source": [
        "history1 = fit(0.001,50,  model, train_loader, valid_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmHwTLdk3Bq-",
        "outputId": "ca6f812e-45c0-487f-88c5-d7ee824abe88"
      },
      "source": [
        "torch.stack(history1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6250, 0.8125, 0.8750, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
              "        0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
              "        0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
              "        0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
              "        0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375, 0.9375,\n",
              "        0.9375, 0.9375, 0.9375, 0.9375, 0.9375])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-7FwwXueVEZ",
        "outputId": "ea94bf52-1821-427e-d56d-5f6a78019ad6"
      },
      "source": [
        "accuracy ## Validation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P58OcB7MsLXQ"
      },
      "source": [
        "dataset2 = MNIST(root='data/', train=False, transform= transforms.ToTensor() )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfiwN4qg1DXS"
      },
      "source": [
        "test_loader= DataLoader(dataset2, batch_size= 128*2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6EKw7rs1NhT"
      },
      "source": [
        "a=[]\r\n",
        "for batch in test_loader:\r\n",
        "  images, labels = batch\r\n",
        "  out = model(images)\r\n",
        "  loss =  F.cross_entropy(out, labels)\r\n",
        "  _ , preds = torch.max(F.softmax(out, dim=1) ,dim=1)\r\n",
        "  accuracy = torch.tensor(torch.sum(preds == labels).item() / len(preds))\r\n",
        "  a.append(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3VvVBoO2Rg_",
        "outputId": "4125172f-2362-45fb-baf6-10017f353181"
      },
      "source": [
        "test_accuracy = torch.stack(a).mean()\r\n",
        "test_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8833)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbKK_5EZ-hKe"
      },
      "source": [
        "def get_default_device():\r\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\r\n",
        "    if torch.cuda.is_available():\r\n",
        "        return torch.device('cuda')\r\n",
        "    else:\r\n",
        "        return torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoFWTtZ28abO",
        "outputId": "210f57f5-628c-4e18-c973-a66ad4ed666e"
      },
      "source": [
        "device = get_default_device()\r\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMxHHuhY-qLj"
      },
      "source": [
        "def to_device(data, device):\r\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\r\n",
        "    if isinstance(data, (list,tuple)):\r\n",
        "        return [to_device(x, device) for x in data]\r\n",
        "    return data.to(device, non_blocking=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ycwqbho_C_K"
      },
      "source": [
        "class DeviceDataLoader():\r\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\r\n",
        "    def __init__(self, dl, device):\r\n",
        "        self.dl = dl\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "    def __iter__(self):\r\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\r\n",
        "        for b in self.dl: \r\n",
        "            yield to_device(b, self.device)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        \"\"\"Number of batches\"\"\"\r\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-bL7JoXTUlL"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyhaYfyETSMX"
      },
      "source": [
        "tf.keras.metrics.AUC()\r\n",
        "tf.keras.layers.Dense(hidden_layer_size, activation='sw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgPVYqO4_PVd"
      },
      "source": [
        "train_loader = DeviceDataLoader(train_loader, device)\r\n",
        "val_loader = DeviceDataLoader(valid_loader, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn3cg7bK_T7e",
        "outputId": "dee7c48f-a546-4726-cf35-b4933bf560cc"
      },
      "source": [
        "for xb, yb in val_loader:\r\n",
        "    print('xb.device:', xb.device)\r\n",
        "    print('yb:', yb)\r\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xb.device: cuda:0\n",
            "yb: tensor([7, 2, 4, 1, 5, 7, 3, 7, 6, 5, 3, 6, 7, 4, 2, 4, 5, 4, 6, 6, 6, 1, 9, 4,\n",
            "        9, 6, 2, 6, 8, 1, 2, 6, 5, 3, 9, 4, 3, 8, 2, 6, 7, 8, 6, 0, 7, 3, 2, 9,\n",
            "        5, 8, 0, 5, 2, 1, 1, 6, 2, 4, 5, 9, 8, 4, 0, 1, 8, 9, 1, 9, 1, 5, 7, 9,\n",
            "        6, 9, 8, 1, 1, 9, 0, 6, 0, 4, 3, 7, 9, 4, 3, 5, 0, 3, 9, 6, 0, 2, 9, 5,\n",
            "        9, 8, 8, 4, 8, 2, 7, 5, 2, 2, 2, 7, 0, 6, 2, 5, 6, 1, 1, 4, 9, 5, 2, 1,\n",
            "        5, 1, 1, 1, 1, 6, 8, 0], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}